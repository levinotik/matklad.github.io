<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
<link href="https://matklad.github.io/feed.xml" rel="self" type="application/atom+xml"/>
<link href="https://matklad.github.io" rel="alternate" type="text/html"/>
<updated>2023-08-07T00:47:22.606Z</updated>
<id>https://matklad.github.io/feed.xml</id>
<title type="html">matklad</title>
<subtitle>Yet another programming blog by Alex Kladov aka matklad.</subtitle>
<author><name>Alex Kladov</name></author>

<entry>
<title type="text">Fantastic Learning Resources</title>
<link href="https://matklad.github.io/2023/08/06/fantastic-learning-resources.html" rel="alternate" type="text/html" title="Fantastic Learning Resources" />
<published>2023-08-06T00:00:00+00:00</published>
<updated>2023-08-06T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/08/06/fantastic-learning-resources</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[People sometimes ask me: Alex, how do I learn X?. This article is a compilation of advice I
usually give. This is things that worked for me rather than the most awesome things on earth. I
do consider every item on the list to be fantastic though, and I am forever grateful to people
putting these resources together.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/08/06/fantastic-learning-resources.html"><![CDATA[
    <h1>
    <a href="#Fantastic-Learning-Resources"><span>Fantastic Learning Resources</span> <time datetime="2023-08-06">Aug 6, 2023</time></a>
    </h1>
<p><span>People sometimes ask me: </span>&ldquo;<span>Alex, how do I learn X?</span>&rdquo;<span>. This article is a compilation of advice I</span>
<span>usually give. This is </span>&ldquo;<span>things that worked for me</span>&rdquo;<span> rather than </span>&ldquo;<span>the most awesome things on earth</span>&rdquo;<span>. I</span>
<span>do consider every item on the list to be fantastic though, and I am forever grateful to people</span>
<span>putting these resources together.</span></p>
<section id="Learning-to-Code">

    <h2>
    <a href="#Learning-to-Code"><span>Learning to Code</span> </a>
    </h2>
<p><span>I don</span>&rsquo;<span>t think I have any useful advice on how to learn programming from zero. The rest of the post</span>
<span>assumes that you at least can, given sufficient time, write simple programs. E.g., a program that</span>
<span>reads a list of integers from an input textual file, sorts them using a quadratic algorithm, and</span>
<span>writes the result to a different file.</span></p>
</section>
<section id="Project-Euler">

    <h2>
    <a href="#Project-Euler"><span>Project Euler</span> </a>
    </h2>
<p><a href="https://projecteuler.net/archives" class="url">https://projecteuler.net/archives</a><span> is fantastic. The first 50 problems or so are a perfect </span>&ldquo;<span>drill</span>&rdquo;
<span>to build programming muscle, to go from </span>&ldquo;<span>I can write a program to sort a list of integers</span>&rdquo;<span> to </span>&ldquo;<span>I can</span>
<em><span>easily</span></em><span> write a program to sort a list of integers</span>&rdquo;<span>.</span></p>
<p><span>Later problems are very heavily math based. If you are mathematically inclined, this is perfect </span>&mdash;
<span>you got to solve fun puzzles while also practicing coding. If advanced math isn</span>&rsquo;<span>t your cup of tea,</span>
<span>feel free to stop doing problems as soon as it stops being fun.</span></p>
</section>
<section id="Modern-Operating-System">

    <h2>
    <a href="#Modern-Operating-System"><span>Modern Operating System</span> </a>
    </h2>
<p><a href="https://en.wikipedia.org/wiki/Modern_Operating_Systems" class="url">https://en.wikipedia.org/wiki/Modern_Operating_Systems</a><span> is fantastic. A </span><a href="https://en.wikipedia.org/wiki/Operating_Systems:_Design_and_Implementation"><span>version of the</span>
<span>book</span></a><span> was the first</span>
<span>thick programming related tome I devoured. It gives a big picture of the inner workings of software</span>
<span>stack, and was a turning point for me personally. After reading this book I realized that I want to</span>
<span>be a programmer.</span></p>
</section>
<section id="Nand-to-Tetris">

    <h2>
    <a href="#Nand-to-Tetris"><span>Nand to Tetris</span> </a>
    </h2>
<p><a href="https://www.nand2tetris.org" class="url">https://www.nand2tetris.org</a><span> is fantastic. It plays a similar </span>&ldquo;<span>big picture</span>&rdquo;<span> role as MOS,</span>
<span>but this time you are the painter. In this course you build a whole computing system yourself,</span>
<span>starting almost from nothing. It doesn</span>&rsquo;<span>t teach you how the real software/hardware stack works, but</span>
<span>it thoroughly dispels any magic, and is extremely fun.</span></p>
</section>
<section id="CSES-Problem-Set">

    <h2>
    <a href="#CSES-Problem-Set"><span>CSES Problem Set</span> </a>
    </h2>
<p><a href="https://cses.fi/problemset/" class="url">https://cses.fi/problemset/</a><span> is fantastic. This is a list of algorithmic problems, which is</span>
<span>meticulously crafted to cover all the standard topics to a reasonable depth. This is by far the best</span>
<span>source for practicing algorithms.</span></p>
</section>
<section id="Programming-Languages">

    <h2>
    <a href="#Programming-Languages"><span>Programming Languages</span> </a>
    </h2>
<p><a href="https://www.coursera.org/learn/programming-languages" class="url">https://www.coursera.org/learn/programming-languages</a><span> is fantastic. This course is a whirlwind tour</span>
<span>across several paradigms of programming, and makes you really </span><em><span>get</span></em><span> what programming languages are</span>
<span>about (and variance).</span></p>
</section>
<section id="Compilers">

    <h2>
    <a href="#Compilers"><span>Compilers</span> </a>
    </h2>
<p><a href="http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=Compilers" class="url">http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=Compilers</a><span> is fantastic. In this</span>
<span>course, you implement a working compiler for a simple, but real programming language. Note that you</span>
<span>can implement your compiler in any language.</span></p>
</section>
<section id="Software-Architecture">

    <h2>
    <a href="#Software-Architecture"><span>Software Architecture</span> </a>
    </h2>
<p><a href="https://www.tedinski.com/archive/" class="url">https://www.tedinski.com/archive/</a><span> is fantastic. Work through the whole archive in chronological</span>
<span>order. This is by far the best resource on </span>&ldquo;<span>programming in the large</span>&rdquo;<span>.</span></p>
</section>
<section id="Random-Bits-of-Advice">

    <h2>
    <a href="#Random-Bits-of-Advice"><span>Random Bits of Advice</span> </a>
    </h2>
<p><span>What follows are some things I</span>&rsquo;<span>ve learned for myself. Take with a pinch of salt!</span></p>
<section id="On-Mentorship">

    <h3>
    <a href="#On-Mentorship"><span>On Mentorship</span> </a>
    </h3>
<p><span>Having a great mentor is fantastic, but mentors are not always available. Luckily, programming can</span>
<span>be mastered without a mentor, if you got past the initial learning step. When you code, you get </span><em><span>a</span>
<span>lot</span></em><span> of feedback, and, through trial and error, you can process the feedback to improve your skills.</span>
<span>In fact, the hardest bit is actually finding the problems to solve (and this article suggests many).</span>
<span>But if you have the problem, you can self-improve noticing the following:</span></p>
<ul>
<li>
<span>How you verify that the solution works.</span>
</li>
<li>
<span>Common bugs and techniques to avoid them in the future.</span>
</li>
<li>
<span>Length of the solution: can you solve the problem using shorter, simpler code?</span>
</li>
<li>
<span>Techniques </span>&mdash;<span> can you apply anything you</span>&rsquo;<span>ve read about this week? How would the problem be solved</span>
<span>in Haskell? Could you apply pattern from language X in language Y?</span>
</li>
</ul>
<p><span>In this context it is important to solve the same problem repeatedly. E.g., you could try solving</span>
<span>the same model problem in all languages you know, with a month or two break between attempts.</span>
<span>Repeatedly doing the same thing and noticing differences and similarities between tries is the</span>
<span>essence of self-learning.</span></p>
</section>
<section id="On-Programming-Languages">

    <h3>
    <a href="#On-Programming-Languages"><span>On Programming Languages</span> </a>
    </h3>
<p><span>Learning your first programming language is a nightmare, because you are learning your editing</span>
<span>environment (PyScripter, IntelliJ IDEA, VS Code) first, simple algorithms second, and the language</span>
<span>itself third. It gets much easier afterwards!</span></p>
<p><span>Learning different programming languages is one of the best way to improve your programming skills.</span>
<span>By seeing what</span>&rsquo;<span>s similar, and what</span>&rsquo;<span>s different, you deeper learn how the things work under the hood.</span>
<span>Different languages put different idioms to the forefront, and learning several expands your</span>
<span>vocabulary considerably. As a bonus, after learning N languages, learning N+1st becomes a question</span>
<span>of skimming through the official docs.</span></p>
<p><span>In general, you want to cover big families of languages: Python, Java, Haskell, C, Rust, Clojure</span>
<span>would be a good baseline. Erlang, Forth, and Prolog would be good additions afterwards.</span></p>
</section>
<section id="On-Algorithms">

    <h3>
    <a href="#On-Algorithms"><span>On Algorithms</span> </a>
    </h3>
<p><span>There are three levels of learning algorithms</span></p>
<dl>
<dt><span>Level 1</span></dt>
<dd>
<p><span>You are not actually learning algorithms, you are learning programming. At this stage, it doesn</span>&rsquo;<span>t</span>
<span>matter how long your code is, how pretty it is, or how efficient it is. The only thing that</span>
<span>matters is that it solve the problem. Generally, this level ends when you are fairly comfortable</span>
<span>with recursion. Few first problems from Project Euler are a great resource here.</span></p>
</dd>
<dt><span>Level 2</span></dt>
<dd>
<p><span>Here you learn algorithms proper. The goal here is mostly encyclopedic knowledge of common</span>
<span>techniques. There are quite a few, but not too many of those. At this stage, the most useful thing</span>
<span>is understanding the math behind the algorithms </span>&mdash;<span> being able to explain algorithm using</span>
<span>pencil&amp;paper, prove its correctness, and analyze Big-O runtime. Generally, you want to learn the</span>
<span>name of algorithm or technique, read and grok the full explanation, and then implement it.</span></p>
<p><span>I recommend doing an abstract implementation first (i.e., not </span>&ldquo;<span>HashMap to solve problem X</span>&rdquo;<span>, but</span>
&ldquo;<span>just HashMap</span>&rdquo;<span>). Include tests in your implementation. Use randomized testing (e.g., when testing</span>
<span>sorting algorithms, don</span>&rsquo;<span>t use a finite set of example, generate a million random ones).</span></p>
<p><span>It</span>&rsquo;<span>s OK and even desirable to implement the same algorithm multiple times. When solving problems,</span>
<span>like CSES, you </span><em><span>could</span></em><span> abstract your solutions and re-use them, but it</span>&rsquo;<span>s better to code everything</span>
<span>from scratch every time, until you</span>&rsquo;<span>ve fully internalized the algorithm.</span></p>
</dd>
<dt><span>Level 3</span></dt>
<dd>
<p><span>One day, long after I</span>&rsquo;<span>ve finished my university, I was a TA for an algorithms course. The lecturer</span>
<span>for the course was the person who originally taught me to program, through a similar algorithms</span>
<span>course. And, during one coffee break, he said something like</span></p>

<figure class="blockquote">
<blockquote><p><span>We don</span>&rsquo;<span>t teach algorithms so that students can code Dijkstra with their eyes closed on the job.</span>
<span>They probably won</span>&rsquo;<span>t have to code any fancy algorithms themselves.</span></p>
<p><span>We teach algorithms so that students learn to think about invariants and properties when writing</span>
<span>code. Real-life code is usually simple enough that it mostly works if you just throw spaghetti</span>
<span>onto the wall. But it doesn</span>&rsquo;<span>t always work. To write correct, robust code at work, you need to</span>
<span>think about invariants.</span></p>
<p><span>The trick with algorithms is that coding them is hard. The only way to avoid bugs is to force</span>
<span>yourself to think in terms of invariants.</span></p>
</blockquote>

</figure>
<p><span>I was thunderstruck! I didn</span>&rsquo;<span>t realize that</span>&rsquo;<span>s the reason why I am learning (well, teaching at that</span>
<span>point) algorithms! Before, I always muddled through my algorithms by randomly tweaking generally</span>
<span>correct stuff until it works. E.g., with a binary search, just add </span><code>+1</code><span> somewhere until it doesn</span>&rsquo;<span>t</span>
<span>loop on random arrays. After hearing this advice, I went home and wrote my millionth binary</span>
<span>search, but this time I actually added comments with loop invariants, and it worked from the first</span>
<span>try! I applied similar techniques for the rest of the course, and since then my subjective</span>
<span>perception of bug rate (for normal work code) went down dramatically.</span></p>
<p><span>So this is the third level of algorithms </span>&mdash;<span> you hone your coding skills to program without bugs.</span>
<span>If you are already fairly comfortable with algorithms, try doing CSES again. But this time, spend</span>
<span>however much you need double-checking the code </span><em><span>before</span></em><span> submission, but try to get everything</span>
<span>correct on the first try.</span></p>
</dd>
</dl>
</section>
<section id="On-Algorithm-Names">

    <h3>
    <a href="#On-Algorithm-Names"><span>On Algorithm Names</span> </a>
    </h3>
<p><span>Here</span>&rsquo;<span>s the list of things you might want to be able to do, algorithmically. You don</span>&rsquo;<span>t need to be</span>
<span>able to code everything on the spot. I think it would help if you know what each word is about, and</span>
<span>have implemented the thing at least once in the past.</span></p>
<p><span>Linear search, binary search, quadratic sorting, quick sort, merge sort, heap sort, binary heap,</span>
<span>growable array (aka ArrayList, vector), doubly-linked list, binary search tree, avl tree, red-black</span>
<span>tree, B-tree, splay tree, hash table (chaining and open addressing), depth first search, breadth first</span>
<span>search, topological sort, strongly connected components, minimal spanning tree (Prim &amp; Kruskal),</span>
<span>shortest paths (bfs, Dijkstra, Floyd–Warshall, Bellman–Ford), substring search (quadratic,</span>
<span>Rabin-Karp, Boyer-Moore, Knuth-Morris-Pratt), trie, Aho-Corasick, dynamic programming (longest</span>
<span>common subsequence, edit distance).</span></p>
</section>
<section id="On-Larger-Programs">

    <h3>
    <a href="#On-Larger-Programs"><span>On Larger Programs</span> </a>
    </h3>
<p><span>A very powerful exercise is coding a medium-sized project from scratch. Something that takes more</span>
<span>than a day, but less than a week, and has a meaningful architecture which can be just right, or</span>
<span>messed up. Here are some great projects to do:</span></p>
<dl>
<dt><span>Ray Tracer</span></dt>
<dd>
<p><span>Given an analytical description of a 3D scene, convert it to a colored 2D image, by simulating a</span>
<span>path of a ray of light as it bounces off objects.</span></p>
</dd>
<dt><span>Software Rasterizer</span></dt>
<dd>
<p><span>Given a description of a 3D scene as a set of triangles, convert it to a colored 2D image by</span>
<span>projecting triangles onto the viewing plane and drawing the projections in the correct order.</span></p>
</dd>
<dt><span>Dynamically Typed Programming Language</span></dt>
<dd>
<p><span>An </span><em><span>interpreter</span></em><span> which reads source code as text, parses it into an AST, and directly executes the</span>
<span>AST (or maybe converts AST to the byte code fore some speed up)</span></p>
</dd>
<dt><span>Statically Typed Programming Language</span></dt>
<dd>
<p><span>A </span><em><span>compiler</span></em><span> which reads source code as text, and spits out a binary (WASM would be a terrific</span>
<span>target).</span></p>
</dd>
<dt><span>Relational Database</span></dt>
<dd>
<p><span>Several components:</span></p>
<ul>
<li>
<span>Storage engine, which stores data durably on disk and implements on-disk ordered data structures</span>
<span>(B-tree or LSM)</span>
</li>
<li>
<span>Relational data model which is implemented on top of primitive ordered data structures.</span>
</li>
<li>
<span>Relational language to express schema and queries.</span>
</li>
<li>
<span>Either a TCP server to accept transactions as a database server, or an API for embedding for an</span>
<span>in-processes </span>&ldquo;<span>embedded</span>&rdquo;<span> database.</span>
</li>
</ul>
</dd>
<dt><span>Chat Server</span></dt>
<dd>
<p><span>An exercise in networking and asynchronous programming. Multiple client programs connect to a</span>
<span>server program. A client can send a message either to a specific different client, or to all other</span>
<span>clients (broadcast). There are many variations on how to implement this: blocking read/write</span>
<span>calls, </span><code>epoll</code><span>, </span><code>io_uring</code><span>, threads, callbacks, futures, manually-coded state machines.</span></p>
</dd>
</dl>
<p><span>Again, it</span>&rsquo;<span>s more valuable to do the same exercise six times with variations, than to blast through</span>
<span>everything once.</span></p>
</section>
</section>
]]></content>
</entry>

<entry>
<title type="text">On Modularity of Lexical Analysis</title>
<link href="https://matklad.github.io/2023/08/01/on-modularity-of-lexical-analysis.html" rel="alternate" type="text/html" title="On Modularity of Lexical Analysis" />
<published>2023-08-01T00:00:00+00:00</published>
<updated>2023-08-01T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/08/01/on-modularity-of-lexical-analysis</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[I was going to write a long post about designing an IDE-friendly language. I wrote an intro and
figured that it would make a better, shorter post on its own. Enjoy!]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/08/01/on-modularity-of-lexical-analysis.html"><![CDATA[
    <h1>
    <a href="#On-Modularity-of-Lexical-Analysis"><span>On Modularity of Lexical Analysis</span> <time datetime="2023-08-01">Aug 1, 2023</time></a>
    </h1>
<p><span>I was going to write a long post about designing an IDE-friendly language. I wrote an intro and</span>
<span>figured that it would make a better, shorter post on its own. Enjoy!</span></p>
<p><span>The big idea of language server construction is that language servers are not magic </span>&mdash;<span> capabilities</span>
<span>and performance of tooling are constrained by the syntax and semantics of the underlying language.</span>
<span>If a language is not designed with toolability in mind, some capabilities (e.g, fully automated</span>
<span>refactors) are impossible to implement correctly. What</span>&rsquo;<span>s more, an IDE-friendly language turns out to</span>
<span>be a fast-to-compile language with easy-to-compose libraries!</span></p>
<p><span>More abstractly, there</span>&rsquo;<span>s this cluster of unrelated at a first sight, but intimately intertwined and</span>
<span>mutually supportive properties:</span></p>
<ul>
<li>
<span>parallel, separate compilation,</span>
</li>
<li>
<span>incremental compilation,</span>
</li>
<li>
<span>resilience to errors.</span>
</li>
</ul>
<p><span>Separate compilation measures how fast we can compile codebase from scratch if we have unlimited</span>
<span>number of CPU cores. For a language server, it solves the cold start problem </span>&mdash;<span> time to</span>
<span>code-completion when the user opens the project for the first time or switches branches. Incremental</span>
<span>compilation is the steady state of the language server </span>&mdash;<span> user types code and expects to see</span>
<span>immediate effects throughout the project. Resilience to errors is important for two different</span>
<span>sub-reasons. First, when the user edits the code it is by definition incomplete and erroneous, but a</span>
<span>language server still must analyze the surrounding context correctly. But the killer feature of</span>
<span>resilience is that, if you are absolutely immune to some errors, you don</span>&rsquo;<span>t even have to look at the</span>
<span>code. If a language server can ignore errors in function bodies, it doesn</span>&rsquo;<span>t have to look at the</span>
<span>bodies of functions from dependencies.</span></p>
<p><span>All three properties, parallelism, incrementality, and resilience, boil down to modularity </span>&mdash;
<span>partitioning the code into disjoint components with well-defined interfaces, such that each</span>
<span>particular component is aware only about the interfaces of other components.</span></p>
<section id="Minimized-Example-Lexical-Analysis">

    <h2>
    <a href="#Minimized-Example-Lexical-Analysis"><span>Minimized Example: Lexical Analysis</span> </a>
    </h2>
<p><span>Lets do a short drill and observe how the three properties interact at a small scale. Let</span>&rsquo;<span>s</span>
<span>minimize the problem of separate compilation to just </span>&hellip;<span> lexical analysis. How can we build a</span>
<span>language that is easier to tokenize for an language server?</span></p>
<p><span>An unclosed quote is a nasty little problem! Practically, it is rare enough that it doesn</span>&rsquo;<span>t really</span>
<span>matter how you handle it, but qualitatively it is illuminating. In a language like Rust, where</span>
<span>strings can span multiple lines, inserting a </span><code>"</code><span> in the middle of a file changes the lexical structure</span>
<span>of the following text completely (</span><code>/*</code><span>, start of a block comment, has the same effect). When tokens</span>
<span>change, so does the syntax tree and the set of symbols defined by the file. A tiny edit, just one</span>
<span>symbol, unhinges semantic structure of the entire compilation unit.</span></p>
<p><span>Zig solves this problem. In Zig, no token can span several lines. That is, it would be correct to</span>
<span>first split Zig source file by </span><code>\n</code><span>, and then tokenize each line separately. This is achieved by</span>
<span>solving underlying problems requiring multi-line tokens better. Specifically:</span></p>
<ul>
<li>
<p><span>there</span>&rsquo;<span>s a single syntax for comments, </span><code>//</code><span>,</span></p>
</li>
<li>
<p><span>double-quoted strings can</span>&rsquo;<span>t contain a </span><code>\n</code><span>,</span></p>
</li>
<li>
<p><span>but there</span>&rsquo;<span>s a really nice syntax for multiline strings:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> greeting =</code>
<code>    <span class="hl-string">\\This is</span></code>
<code>    <span class="hl-string">\\a multiline string</span></code>
<code>    <span class="hl-string">\\   &lt;- with a leading whitespace here.</span></code>
<code>    <span class="hl-string">\\</span></code></pre>

</figure>
</li>
</ul>
<p><span>Do you see modules here? Disjoint-partitioning into interface-connected components? From the</span>
<span>perspective of lexical analysis, each </span><em><span>line</span></em><span> is a module. And a line always has a trivial, empty</span>
<span>interface </span>&mdash;<span> different lines are completely independent. As a result:</span></p>
<p><em><span>First</span></em><span>, we can do lexical analysis in parallel. If you have N CPU cores, you can split file into N</span>
<span>equal chunks, then in parallel locally adjust chunk boundaries such that they fall on newlines, and</span>
<span>then tokenize each chunk separately.</span></p>
<p><em><span>Second</span></em><span>, we have quick incremental tokenization </span>&mdash;<span> given a source edit, you determine the set of</span>
<span>lines affected, and re-tokenize only those. The work is proportional to the size of the edit plus at</span>
<span>most two boundary lines.</span></p>
<p><em><span>Third</span></em><span>, any lexical error in a line is isolated just to this line. There</span>&rsquo;<span>s no unclosed quote</span>
<span>problem, mistakes are contained.</span></p>
<p><span>I am by no means saying that line-by-line lexing is a requirement for an IDE-friendly language</span>
<span>(though it would be nice)! Rather, I want you to marvel how the same underlying structure of the</span>
<span>problem can be exploited for quarantining errors, reacting to changes quickly, and parallelizing the</span>
<span>processing.</span></p>
<p><span>The three properties are just three different faces of modularity in the end!</span></p>
<hr>
<p><span>I do want to write that </span>&ldquo;<span>IDE-friendly language</span>&rdquo;<span> post at some point, but, as a hedge (after all, I</span>
<span>still owe you </span>&ldquo;<a href="https://matklad.github.io/2022/04/25/why-lsp.html"><span>Why LSP</span></a><span> Sucks?</span>&rdquo;<span> one</span>&hellip;<span>), here are two comments where I explored the idea somewhat:</span>
<a href="https://todo.sr.ht/~icefox/garnet/52#event-242650"><span>1</span></a><span>,</span>
<a href="https://lobste.rs/s/u7y4lk/modules_matter_most_for_masses#c_i6a8n9"><span>2</span></a><span>.</span></p>
<p><span>I also recommend these posts, which explore the same underlying phenomenon from the software</span>
<span>architecture perspective:</span></p>
<ul>
<li>
<a href="https://www.tedinski.com/2018/01/30/the-one-ring-problem-abstraction-and-power.html" class="url">https://www.tedinski.com/2018/01/30/the-one-ring-problem-abstraction-and-power.html</a>
</li>
<li>
<a href="https://www.tedinski.com/2018/02/06/system-boundaries.html" class="url">https://www.tedinski.com/2018/02/06/system-boundaries.html</a>
</li>
<li>
<a href="https://www.pathsensitive.com/2023/03/modules-matter-most-for-masses.html" class="url">https://www.pathsensitive.com/2023/03/modules-matter-most-for-masses.html</a>
</li>
</ul>
</section>
]]></content>
</entry>

<entry>
<title type="text">Three Different Cuts</title>
<link href="https://matklad.github.io/2023/07/16/three-different-cuts.html" rel="alternate" type="text/html" title="Three Different Cuts" />
<published>2023-07-16T00:00:00+00:00</published>
<updated>2023-07-16T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/07/16/three-different-cuts</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[In this post, we'll look at how Rust, Go, and Zig express the signature of function cut --- the power tool of string manipulation.
Cut takes a string and a pattern, and splits the string around the first occurrence of the pattern:
cut("life", "if") = ("l", "e").]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/07/16/three-different-cuts.html"><![CDATA[
    <h1>
    <a href="#Three-Different-Cuts"><span>Three Different Cuts</span> <time datetime="2023-07-16">Jul 16, 2023</time></a>
    </h1>
<p><span>In this post, we</span>&rsquo;<span>ll look at how Rust, Go, and Zig express the signature of function </span><code>cut</code><span> </span>&mdash;<span> the power tool of string manipulation.</span>
<span>Cut takes a string and a pattern, and splits the string around the first occurrence of the pattern:</span>
<span class="display"><code>cut("life", "if") = ("l", "e")</code><span>.</span></span></p>
<p><span>At a glance, it seems like a non-orthogonal jumbling together of searching and slicing.</span>
<span>However, in practice a lot of ad-hoc string processing can be elegantly expressed via </span><code>cut</code><span>.</span></p>
<p><span>A lot of things are </span><code>key=value</code><span> pairs, and cut fits perfectly there.</span>
<span>What</span>&rsquo;<span>s more, many more complex sequencies, like</span>
<span class="display"><code>--arg=key=value</code><span>,</span></span>
<span>can be viewed as nested pairs.</span>
<span>You can cut around </span><code>=</code><span> once to get </span><code>--arg</code><span> and </span><code>key=value</code><span>, and then cut the second time to separate </span><code>key</code><span> from </span><code>value</code><span>.</span></p>
<p><span>In Rust, this function looks like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">split_once</span>&lt;<span class="hl-symbol">&#x27;a</span>, P&gt;(</code>
<code>  &amp;<span class="hl-symbol">&#x27;a</span> <span class="hl-keyword">self</span>,</code>
<code>  delimiter: P,</code>
<code>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">Option</span>&lt;(&amp;<span class="hl-symbol">&#x27;a</span> <span class="hl-type">str</span>, &amp;<span class="hl-symbol">&#x27;a</span> <span class="hl-type">str</span>)&gt;</code>
<code><span class="hl-keyword">where</span></code>
<code>  P: Pattern&lt;<span class="hl-symbol">&#x27;a</span>&gt;,</code>
<code>{</code>
<code>}</code></pre>

</figure>
<p><span>Rust</span>&rsquo;<span>s </span><code>Option</code><span> is a good fit for the result type, it clearnly describes the behavior of the function when the pattern isn</span>&rsquo;<span>t found in the string at all.</span>
<span>Lifetime </span><code>'a</code><span> expresses the relationship between the result and the input </span>&mdash;<span> both pieces of result are substrings of </span><code>&amp;'a self</code><span>, so, as long as they are used, the original string must be kept alive as well.</span>
<span>Finally, the separator isn</span>&rsquo;<span>t another string, but a generic </span><code>P: Pattern</code><span>.</span>
<span>This gives a somewhat crowded signature, but allows using strings, single characters, and even </span><code class="display">fn(c: char) -&gt; bool</code><span> functions as patterns.</span></p>
<p><span>When using the function, there are is a multitude of ways to access the result:</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// Propagate `None` upwards:</span></code>
<code><span class="hl-keyword">let</span> (prefix, suffix) = line.<span class="hl-title function_ invoke__">split_once</span>(<span class="hl-string">&quot;=&quot;</span>)?;</code>
<code></code>
<code><span class="hl-comment">// Handle `None` in an ad-hoc way:</span></code>
<code><span class="hl-keyword">let</span> <span class="hl-variable">Some</span>((prefix, suffix)) = line.<span class="hl-title function_ invoke__">split_once</span>(<span class="hl-string">&quot;=&quot;</span>) <span class="hl-keyword">else</span> {</code>
<code>    <span class="hl-keyword">return</span></code>
<code>};</code>
<code></code>
<code><span class="hl-comment">// Ignore `None`:</span></code>
<code><span class="hl-keyword">if</span> <span class="hl-keyword">let</span> <span class="hl-variable">Some</span>((prefix, suffix)) = line.<span class="hl-title function_ invoke__">split_once</span>(<span class="hl-string">&quot;=&quot;</span>) {</code>
<code>    ...</code>
<code>};</code>
<code></code>
<code><span class="hl-comment">// Handle `Some` and `None` in a symmetric way:</span></code>
<code><span class="hl-keyword">let</span> <span class="hl-variable">result</span> = <span class="hl-keyword">match</span> line.<span class="hl-title function_ invoke__">split_once</span>(<span class="hl-string">&quot;=&quot;</span>) {</code>
<code>    <span class="hl-title function_ invoke__">Some</span>((prefix, suffix)) =&gt; { ... }</code>
<code>    <span class="hl-literal">None</span> =&gt; { ... }</code>
<code>};</code>
<code></code>
<code><span class="hl-comment">// Access only one component of the result:</span></code>
<code><span class="hl-keyword">let</span> <span class="hl-variable">suffix</span> = line.<span class="hl-title function_ invoke__">split_once</span>(<span class="hl-string">&quot;=&quot;</span>)?.<span class="hl-number">1</span>;</code>
<code></code>
<code><span class="hl-comment">// Use high-order functions to extract key with a default:</span></code>
<code><span class="hl-keyword">let</span> <span class="hl-variable">key</span> = line.<span class="hl-title function_ invoke__">split_once</span>(<span class="hl-string">&quot;=&quot;</span>)</code>
<code>    .<span class="hl-title function_ invoke__">map</span>(|(key, _value)| key)</code>
<code>    .<span class="hl-title function_ invoke__">unwrap_or</span>(line);</code></pre>

</figure>
<p><span>Here</span>&rsquo;<span>s a Go equivalent:</span></p>

<figure class="code-block">


<pre><code><span class="hl-function"><span class="hl-keyword">func</span> <span class="hl-title">Cut</span><span class="hl-params">(s, sep <span class="hl-type">string</span>)</span></span> (before, after <span class="hl-type">string</span>, found <span class="hl-type">bool</span>) {</code>
<code>    ...</code>
<code>}</code></pre>

</figure>
<p><span>It has a better name!</span>
<span>It</span>&rsquo;<span>s important that frequently used building-block functions have short, memorable names, and </span>&ldquo;<span>cut</span>&rdquo;<span> is just perfect for what the function does.</span>
<span>Go doesn</span>&rsquo;<span>t have an </span><code>Option</code><span>, but it allows multiple return values, and any type in Go has a zero value, so a boolean flag can be used to signal </span><code>None</code><span>.</span>
<span>Curiously if the </span><code>sep</code><span> is not found in </span><code>s</code><span>, </span><code>after</code><span> is set to </span><code>""</code><span>, but </span><code>before</code><span> is set to </span><code>s</code><span> (that is, the whole string).</span>
<span>This is occasionally useful, and corresponds to the last Rust example.</span>
<span>But it also isn</span>&rsquo;<span>t something immediately obvious from the signature, it</span>&rsquo;<span>s an extra detail to keep in mind.</span>
<span>Which might be fine for a foundational function!</span>
<span>Similarly to Rust, the resulting strings point to the same memory as </span><code>s</code><span>.</span>
<span>There are no lifetimes, but a potential performance gotcha </span>&mdash;<span> if one of the resulting strings is alive, then the entire </span><code>s</code><span> can</span>&rsquo;<span>t be garbage collected.</span></p>
<p><span>There isn</span>&rsquo;<span>t much in way of using the function in Go:</span></p>

<figure class="code-block">


<pre><code>prefix, suffix, ok = strings.Cut(line, <span class="hl-string">&quot;=&quot;</span>)</code>
<code><span class="hl-keyword">if</span> !ok {</code>
<code>    ...</code>
<code>}</code></pre>

</figure>
<p><span>Zig doesn</span>&rsquo;<span>t yet have an equivalent function in its standard library, but it probably will at some point, and the signature might look like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span><span class="hl-function"> cut</span>(</code>
<code>    s: []<span class="hl-keyword">const</span> <span class="hl-type">u8</span>,</code>
<code>    sep: []<span class="hl-keyword">const</span> <span class="hl-type">u8</span></code>
<code>) ?<span class="hl-keyword">struct</span> { prefix: []<span class="hl-keyword">const</span> <span class="hl-type">u8</span>, suffix: []<span class="hl-keyword">const</span> <span class="hl-type">u8</span> } {</code>
<code>    ...</code>
<code>}</code></pre>

</figure>
<p><span>Similarly to Rust, Zig can express optional values.</span>
<span>Unlike Rust, the option is a built-in, rather than a user-defined type (Zig </span><em><span>can</span></em><span> express a generic user-defined option, but chooses not to).</span>
<span>All types in Zig are strictly prefix, so leading </span><code>?</code><span> concisely signals optionality.</span>
<span>Zig doesn</span>&rsquo;<span>t have first-class tuple types, but uses very concise and flexible type declaration syntax, so we can return a named tuple.</span>
<span>Curiously, this anonymous struct is still a nominal, rather than a structural, type!</span>
<span>Similarly to Rust, </span><code>prefix</code><span> and </span><code>suffix</code><span> borrow the same memory that </span><code>s</code><span> does.</span>
<span>Unlike Rust, this isn</span>&rsquo;<span>t expressed in the signature </span>&mdash;<span> while in this case it is obvious that the lifetime would be bound to </span><code>s</code><span>, rather than </span><code>sep</code><span>, there are no type system guardrails here.</span></p>
<p><span>Because </span><code>?</code><span> is a built-in type, we need some amount of special syntax to handle the result, but it curiously feels less special-case and more versatile than the Rust version.</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// Propagate `null` upwards / handle `null` in an ad-hoc way.</span></code>
<code><span class="hl-keyword">const</span> cut = mem.cut(line, <span class="hl-string">&quot;=&quot;</span>) <span class="hl-keyword">orelse</span> <span class="hl-keyword">return</span> <span class="hl-literal">null</span>;</code>
<code><span class="hl-keyword">const</span> cut = mem.cut(line, <span class="hl-string">&quot;=&quot;</span>) <span class="hl-keyword">orelse</span> <span class="hl-keyword">return</span>;</code>
<code></code>
<code><span class="hl-comment">// Ignore or handle `null`.</span></code>
<code><span class="hl-keyword">if</span> (mem.cut(line, <span class="hl-string">&quot;=&quot;</span>)) <span class="hl-operator">|</span>cut<span class="hl-operator">|</span> {</code>
<code></code>
<code>} <span class="hl-keyword">else</span> {</code>
<code></code>
<code>}</code>
<code></code>
<code><span class="hl-comment">// Go semantics: extract key with a default</span></code>
<code>let key = <span class="hl-keyword">if</span> (mem.cut(line, <span class="hl-string">&quot;=&quot;</span>)) <span class="hl-operator">|</span>cut<span class="hl-operator">|</span> cut.first <span class="hl-keyword">else</span> line;</code></pre>

</figure>
<p><span>Moral of the story?</span>
<span>Work with the grain of the language </span>&mdash;<span> expressing the same concept in different languages usually requires a slightly different vocabulary.</span></p>
]]></content>
</entry>

<entry>
<title type="text">GitHub Merge Queue</title>
<link href="https://matklad.github.io/2023/06/18/GitHub-merge-queue.html" rel="alternate" type="text/html" title="GitHub Merge Queue" />
<published>2023-06-18T00:00:00+00:00</published>
<updated>2023-06-18T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/06/18/GitHub-merge-queue</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[Short, unedited note on GitHub merge queue.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/06/18/GitHub-merge-queue.html"><![CDATA[
    <h1>
    <a href="#GitHub-Merge-Queue"><span>GitHub Merge Queue</span> <time datetime="2023-06-18">Jun 18, 2023</time></a>
    </h1>
<p><span>Short, unedited note on </span><a href="https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/managing-a-merge-queue"><span>GitHub merge queue</span></a><span>.</span></p>
<p><span>TL;DR, </span><a href="https://bors.tech" class="url">https://bors.tech</a><span> delivers a meaningfully better experience, although it suffers from being a third-party integration.</span></p>
<p><span>Specific grievances:</span></p>
<p><em><span>Complexity</span></em><span>. This is a vague feeling, but merge queue feels like it is built by complexity merchants </span>&mdash;<span> there are a lot of unclear settings and voluminous and byzantine docs.</span>
<span>Good for allocating extra budget towards build engineering, bad for actual build engineering.</span></p>
<p><em><span>GUI-only configuration</span></em><span>. Bors is setup using bors.toml in the repository, merge queue is setup by clicking through web GUI.</span>
<span>To share config with other maintainers, I resorted to a zoomed-out screenshot of the page.</span></p>
<p><em><span>Unclear set of checks</span></em><span>. The purpose of the merge queue is to enforce not rocket science rule of software engineering </span>&mdash;<span> making sure that the code in the main branch satisfies certain quality invariants (all tests are passing).</span>
<span>It is impossible to tell what merge queue actually enforces.</span>
<span>Typically, when you enable merge queue, you subsequently find out that it actually merges anything, without any checks whatsoever.</span></p>
<p><em><span>Double latency</span></em><span>. One of the biggest benefits of a merge queue for a high velocity project is its </span><em><span>asynchrony</span></em><span>.</span>
<span>After submitting a PR, you can do a review and schedule PR to be merged </span><em><span>without</span></em><span> waiting for CI to finish.</span>
<span>This is massive: it is 2X reduction to human attention required.</span>
<span>Without queue, you need to look at a PR twice: once to do a review, and once to click merge after the green checkmark is in.</span>
<span>With the queue, you only need a review, and the green checkmark comes in asynchronously.</span>
<span>Except that with GitHub merge queue, you can</span>&rsquo;<span>t actually add a PR to the queue until you get a green checkmark.</span>
<span>In effect, that</span>&rsquo;<span>s still 2X attention, and then a PR runs through the same CI checks twice (yes, you can have separate checks for merge queue and PR. No, this is not a good idea, this is complexity and busywork).</span></p>
<p><em><span>Lack of delegation</span></em><span>. With bors, you can use </span><code>bors delegate+</code><span> to delegate merging of a single, specific pull request to its author.</span>
<span>This is helpful to drive contributor engagement, and to formalize </span>&ldquo;<span>LGTM with the nits fixed</span>&rdquo;<span> approval (which again reduces number of human round trips).</span></p>
<p><span>You still should use GitHub merge queue, rather than bors-ng, as that</span>&rsquo;<span>s now a first-party feature.</span>
<span>Still, its important to understand how things </span><em><span>should</span></em><span> work, to be able to improve state of the art some other time.</span></p>
]]></content>
</entry>

<entry>
<title type="text">The Worst Zig Version Manager</title>
<link href="https://matklad.github.io/2023/06/02/the-worst-zig-version-manager.html" rel="alternate" type="text/html" title="The Worst Zig Version Manager" />
<published>2023-06-02T00:00:00+00:00</published>
<updated>2023-06-02T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/06/02/the-worst-zig-version-manager</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[https://github.com/matklad/hello-getzig]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/06/02/the-worst-zig-version-manager.html"><![CDATA[
    <h1>
    <a href="#The-Worst-Zig-Version-Manager"><span>The Worst Zig Version Manager</span> <time datetime="2023-06-02">Jun 2, 2023</time></a>
    </h1>

<figure class="code-block">
<figcaption class="title">./getzig.ps1</figcaption>


<pre><code>#!/bin/sh</code>
<code>echo `# &lt;#`</code>
<code></code>
<code>mkdir -p ./zig</code>
<code></code>
<code>wget https://ziglang.org/download/0.10.1/zig-linux-x86_64-0.10.1.tar.xz -O ./zig/zig-linux-x86_64-0.10.1.tar.xz</code>
<code>tar -xf ./zig/zig-linux-x86_64-0.10.1.tar.xz -C ./zig --strip-components=1</code>
<code>rm ./zig/zig-linux-x86_64-0.10.1.tar.xz</code>
<code></code>
<code>echo "Zig installed."</code>
<code>./zig/zig version</code>
<code></code>
<code>exit</code>
<code>#&gt; &gt; $null</code>
<code></code>
<code>Invoke-WebRequest -Uri "https://ziglang.org/download/0.10.1/zig-windows-x86_64-0.10.1.zip" -OutFile ".\zig-windows-x86_64-0.10.1.zip"</code>
<code>Expand-Archive -Path ".\zig-windows-x86_64-0.10.1.zip" -DestinationPath ".\" -Force</code>
<code>Remove-Item -Path " .\zig-windows-x86_64-0.10.1.zip"</code>
<code>Rename-Item -Path ".\zig-windows-x86_64-0.10.1" -NewName ".\zig"</code>
<code></code>
<code>Write-Host "Zig installed."</code>
<code>./zig/zig.exe version</code></pre>

</figure>
<p class="display"><a href="https://github.com/matklad/hello-getzig" class="url">https://github.com/matklad/hello-getzig</a></p>
<p><span>Longer version:</span></p>
<p><span>One of the values of Zig which resonates with me deeply is a mindful approach to dependencies.</span>
<span>Zig tries hard not to ask too much from the environment, such that, if you get </span><code>zig version</code><span> running, you can be reasonably sure that everything else works.</span>
<span>That</span>&rsquo;<span>s one of the main motivations for adding an HTTP client to the Zig distribution recently.</span>
<span>Building software today involves downloading various components from the Internet, and, if Zig wants for software built with Zig to be hermetic and self-sufficient, it needs to provide ability to download files from HTTP servers.</span></p>
<p><span>There</span>&rsquo;<span>s one hurdle for self-sufficiency: how do you get Zig in the first place?</span>
<span>One answer to this question is </span>&ldquo;<span>from your distribution</span>&rsquo;<span>s package manager</span>&rdquo;<span>.</span>
<span>This is not a very satisfying answer, at least until the language is both post 1.0 and semi-frozen in development.</span>
<span>And even then, what if your distribution is Windows?</span>
<span>How many distributions should be covered by </span>&ldquo;<span>Installing Zig</span>&rdquo;<span> section of your </span><code>CONTRIBUTING.md</code><span>?</span></p>
<p><span>Another answer would be a version manager, a-la </span><code>rustup</code><span>, </span><code>nvm</code><span>, or </span><code>asdf</code><span>.</span>
<span>These tools work well, but they are quite complex, and rely on various subtle properties of the environment, like </span><code>PATH</code><span>, shell activation scripts and busybox-style multipurpose executable.</span>
<span>And, well, this also kicks the can down the road </span>&mdash;<span> you can use </span><code>zvm</code><span> to get Zig, but how do you get </span><code>zvm</code><span>?</span></p>
<p><span>I like how we do this in </span><a href="https://github.com/tigerbeetledb/tigerbeetle/blob/56d14e82769deb6817809f866253220ae0f499d1/scripts/install_zig.sh"><span>TigerBeetle</span></a><span>.</span>
<span>We don</span>&rsquo;<span>t use </span><code>zig</code><span> from </span><code>PATH</code><span>.</span>
<span>Instead, we just put the correct version of Zig into </span><code>./zig</code><span> folder in the root of the repository, and run it like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-title function_">$</span> ./zig/zig build test</code></pre>

</figure>
<p><span>Suddenly, whole swaths of complexity go away.</span>
<span>Quiz time: if you need to add a directory to </span><code>PATH</code><span>, which script should be edited so that both the graphical environment and the terminal are affected?</span></p>
<p><span>Finally, another interesting case study is Gradle.</span>
<span>Usually Gradle is a negative example, but they do have a good approach for installing Gradle itself.</span>
<span>The standard pattern is to store two scripts, </span><code>gradlew.sh</code><span> and </span><code>gradlew.bat</code><span>, which bootstrap the right version of Gradle by downloading a jar file (java itself is not bootstrapped this way though).</span></p>
<p><span>What all these approaches struggle to overcome is the problem of bootstrapping.</span>
<span>Generally, if you need to automate anything, you can write a program to do that.</span>
<span>But you need some pre-existing program runner!</span>
<span>And there</span>&rsquo;<span>s just no good options out of the box </span>&mdash;<span> bash and powershell are passable, but barely, and they are different.</span>
<span>And </span>&ldquo;<span>bash</span>&rdquo;<span> and the set of coreutils also differs depending on the Unix in question.</span>
<span>But there</span>&rsquo;<span>s just no good solution here </span>&mdash;<span> if you want to bootstrap automatically, you must start with universally available tools.</span></p>
<p><span>But is there perhaps some scripting language which is shared between Windows and Unix?</span>
<a href="https://github.com/cspotcode"><span>@cspotcode</span></a><span> suggests </span><a href="https://cspotcode.com/posts/polyglot-powershell-and-bash-script"><span>a horrible workaround</span></a><span>.</span>
<span>You can write a script which is </span><em><span>both</span></em><span> a bash script and a powershell script.</span>
<span>And it even isn</span>&rsquo;<span>t too too ugly!</span></p>

<figure class="code-block">


<pre><code>!/bin/bash</code>
<code>echo `# &lt;#`</code>
<code></code>
<code>echo "Bash!"</code>
<code></code>
<code>exit</code>
<code>#&gt; &gt; $null</code>
<code></code>
<code>Write-Host "PowerShell!"</code></pre>

</figure>
<p><span>So, here</span>&rsquo;<span>s an idea for a hermetic Zig version management workflow.</span>
<span>There</span>&rsquo;<span>s a canonical, short </span><code>getzig.ps1</code><span> PowerShell/sh script which is vendored verbatim by various projects.</span>
<span>Running this script downloads an appropriate version of Zig, and puts it into </span><code>./zig/zig</code><span> inside the repository (</span><code>.gitignore</code><span> contains </span><code>/zig</code><span>).</span>
<span>Building, testing, and other workflows use </span><code>./zig/zig</code><span> instead of relying on global system state (</span><code>$PATH</code><span>).</span></p>
<p><span>A proof-of-concept </span><code>getzig.ps1</code><span> is at the start of this article.</span>
<span>Note that I don</span>&rsquo;<span>t know bash, powershell, and how to download files from the Internet securely, so the above PoC was mostly written by Chat GPT.</span>
<span>But it seems to work on my machine.</span>
<span>I clone </span><a href="https://github.com/matklad/hello-getzig" class="url">https://github.com/matklad/hello-getzig</a><span> and run</span></p>

<figure class="code-block">


<pre><code><span class="hl-title function_">$</span> ./getzig.ps1</code>
<code><span class="hl-title function_">$</span> ./zig/zig run ./hello.zig</code></pre>

</figure>
<p><span>on both NixOS and Windows 10, and it prints hello.</span></p>
<p><span>If anyone wants to make an actual thing out of this idea, here</span>&rsquo;<span>s possible desiderata:</span></p>
<ul>
<li>
<p><span>A single polyglot </span><code>getzig.sh.ps1</code><span> is cute, but using a couple of different scripts wouldn</span>&rsquo;<span>t be a big problem.</span></p>
</li>
<li>
<p><span>Size of the scripts </span><em><span>could</span></em><span> be a problem, as they are supposed to be vendored into each repository.</span>
<span>I</span>&rsquo;<span>d say 512 lines for combined </span><code>getzig.sh.ps1</code><span> would be a reasonable complexity limit.</span></p>
</li>
<li>
<p><span>The script must </span>&ldquo;<span>just work</span>&rdquo;<span> on all four major desktop operating systems: Linux, Mac, Windows, and WSL.</span></p>
</li>
<li>
<p><span>The script should be polymorphic in </span><code>curl</code><span> / </span><code>wget</code><span> and </span><code>bash</code><span> / </span><code>sh</code><span>.</span></p>
</li>
<li>
<p><span>It</span>&rsquo;<span>s ok if it doesn</span>&rsquo;<span>t work absolutely everywhere </span>&mdash;<span> downloading/building Zig manually for an odd platform is also an acceptable workflow.</span></p>
</li>
<li>
<p><span>The script should auto-detect appropriate host platform and architecture.</span></p>
</li>
<li>
<p><span>Zig version should be specified in a separate </span><code>zig-version.txt</code><span> file.</span></p>
</li>
<li>
<p><span>After downloading the file, its integrity should be verified.</span>
<span>For this reason, </span><code>zig-version.txt</code><span> should include a hash alongside the version.</span>
<span>As downloads are different depending on the platform, I think we</span>&rsquo;<span>ll need some help from Zig upstream here.</span>
<span>In particular, each published Zig version should include a cross-platform manifest file, which lists hashes and urls of per-platform binaries.</span>
<span>The hash included into </span><code>zig-version.txt</code><span> should be the manifest</span>&rsquo;<span>s hash.</span></p>
</li>
</ul>
]]></content>
</entry>

<entry>
<title type="text">Resilient LL Parsing Tutorial</title>
<link href="https://matklad.github.io/2023/05/21/resilient-ll-parsing-tutorial.html" rel="alternate" type="text/html" title="Resilient LL Parsing Tutorial" />
<published>2023-05-21T00:00:00+00:00</published>
<updated>2023-05-21T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/05/21/resilient-ll-parsing-tutorial</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[In this tutorial, I will explain a particular approach to parsing, which gracefully handles syntax errors and is thus suitable for language servers, which, by their nature, have to handle incomplete and invalid code.
Explaining the problem and the solution requires somewhat less than a trivial worked example, and I want to share a couple of tricks not directly related to resilience, so the tutorial builds a full, self-contained parser, instead of explaining abstractly just the resilience.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/05/21/resilient-ll-parsing-tutorial.html"><![CDATA[
    <h1>
    <a href="#Resilient-LL-Parsing-Tutorial"><span>Resilient LL Parsing Tutorial</span> <time datetime="2023-05-21">May 21, 2023</time></a>
    </h1>
<p><span>In this tutorial, I will explain a particular approach to parsing, which gracefully handles syntax errors and is thus suitable for language servers, which, by their nature, have to handle incomplete and invalid code.</span>
<span>Explaining the problem and the solution requires somewhat less than a trivial worked example, and I want to share a couple of tricks not directly related to resilience, so the tutorial builds a full, self-contained parser, instead of explaining abstractly </span><em><span>just</span></em><span> the resilience.</span></p>
<p><span>The tutorial is descriptive, rather than prescriptive </span>&mdash;<span> it tells you what you </span><em><span>can</span></em><span> do, not what you </span><em><span>should</span></em><span> do.</span></p>
<ul>
<li>
<span>If you are looking into building a production grade language server, treat it as a library of ideas, not as a blueprint.</span>
</li>
<li>
<span>If you want to get something working quickly, I think today the best answer is </span>&ldquo;<span>just use </span><a href="https://tree-sitter.github.io"><span>Tree-sitter</span></a>&rdquo;<span>, so you</span>&rsquo;<span>d better read its docs rather than this tutorial.</span>
</li>
<li>
<span>If you are building an IDE-grade parser from scratch, then techniques presented here might be directly applicable.</span>
</li>
</ul>
<section id="Why-Resilience-is-Needed">

    <h2>
    <a href="#Why-Resilience-is-Needed"><span>Why Resilience is Needed?</span> </a>
    </h2>
<p><span>Let</span>&rsquo;<span>s look at one motivational example for resilient parsing:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">fib_rec</span>(f1: <span class="hl-type">u32</span>,</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">fib</span>(n: <span class="hl-type">u32</span>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</code>
<code>  <span class="hl-title function_ invoke__">fib_rec</span>(<span class="hl-number">1</span>, <span class="hl-number">1</span>, n)</code>
<code>}</code></pre>

</figure>
<p><span>Here, a user is in the process of defining the </span><code>fib_rec</code><span> helper function.</span>
<span>For a language server, it</span>&rsquo;<span>s important that the incompleteness doesn</span>&rsquo;<span>t get in the way.</span>
<span>In particular:</span></p>
<ul>
<li>
<p><span>The following function, </span><code>fib</code><span>, should be parsed without any errors such that syntax and semantic highlighting is not disturbed, and all calls to </span><code>fib</code><span> elsewhere typecheck correctly.</span></p>
</li>
<li>
<p><span>The </span><code>fib_rec</code><span> function itself should be recognized as a partially complete function, so that various language server assists can help complete it correctly.</span></p>
</li>
<li>
<p><span>In particular, a smart language server can actually infer the expected type of </span><code>fib_rec</code><span> from a call we already have, and suggest completing the whole prototype.</span>
<span>rust-analyzer doesn</span>&rsquo;<span>t do that today, but one day it should.</span></p>
</li>
</ul>
<p><span>Generalizing this example, what we want from our parser is to recognize as much of the syntactic structure as feasible.</span>
<span>It should be able to localize errors </span>&mdash;<span> a mistake in a function generally should not interfere with parsing unrelated functions.</span>
<span>As the code is read and written left-to-right, the parser should also recognize valid partial prefixes of various syntactic constructs.</span></p>
<p><span>Academic literature suggests another lens to use when looking at this problem: error recovery.</span>
<span>Rather than just recognizing incomplete constructs, the parser can attempt to guess a minimal edit which completes the construct and gets rid of the syntax error.</span>
<span>From this angle, the above example would look rather like </span><span class="display"><code>fn fib_rec(f1: u32, /* ) {} */</code><span> ,</span></span><span> where the stuff in a comment is automatically inserted by the parser.</span></p>
<p><span>Resilience is a more fruitful framing to use for a language server </span>&mdash;<span> incomplete code is the ground truth, and only the user knows how to correctly complete it.</span>
<span>An language server can only offer guesses and suggestions, and they are more precise if they employ post-parsing semantic information.</span></p>
<p><span>Error recovery might work better when emitting understandable syntax errors, but, in a language server, the importance of clear error messages for </span><em><span>syntax</span></em><span> errors is relatively lower, as highlighting such errors right in the editor synchronously with typing usually provides tighter, more useful tacit feedback.</span></p>
</section>
<section id="Approaches-to-Error-Resilience">

    <h2>
    <a href="#Approaches-to-Error-Resilience"><span>Approaches to Error Resilience</span> </a>
    </h2>
<p><span>The classic approach for handling parser errors is to explicitly encode error productions and synchronization tokens into the language grammar.</span>
<span>This approach isn</span>&rsquo;<span>t a natural fit for resilience framing </span>&mdash;<span> you don</span>&rsquo;<span>t want to anticipate every possible error, as there are just too many possibilities.</span>
<span>Rather, you want to recover as much of a valid syntax tree as possible, and more or less ignore arbitrary invalid parts.</span></p>
<p><span>Tree-sitter does something more interesting.</span>
<span>It is a </span><strong><strong><span>G</span></strong></strong><span>LR parser, meaning that it non-deterministically tries many possible LR (bottom-up) parses, and looks for the best one.</span>
<span>This allows Tree-sitter to recognize many complete valid small fragments of a tree, but it might have trouble assembling them into incomplete larger fragments.</span>
<span>In our example </span><span class="display"><code>fn fib_rec(f1: u32,</code><span> ,</span></span><span> Tree-sitter correctly recognizes </span><code>f1: u32</code><span> as a formal parameter, but doesn</span>&rsquo;<span>t recognize </span><code>fib_rec</code><span> as a function.</span></p>
<p><span>Top-down (LL) parsing paradigm makes it harder to recognize valid small fragments, but naturally allows for incomplete large nodes.</span>
<span>Because code is written top-down and left-to-right, LL seems to have an advantage for typical patterns of incomplete code.</span>
<span>Moreover, there isn</span>&rsquo;<span>t really anything special you need to do to make LL parsing resilient.</span>
<span>You sort of</span>&hellip;<span> just not crash on the first error, and everything else more or less just works.</span></p>
<p><span>Details are fiddly though, so, in the rest of the post, we will write a complete implementation of a hand-written recursive descent + Pratt resilient parser.</span></p>
</section>
<section id="Introducing-L">

    <h2>
    <a href="#Introducing-L"><span>Introducing L</span> </a>
    </h2>
<p><span>For the lack of imagination on my side, the toy language we will be parsing is called </span><code>L</code><span>.</span>
<span>It is a subset of Rust, which has just enough features to make some syntax mistakes.</span>
<span>Here</span>&rsquo;<span>s Fibonacci:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">fib</span>(n: <span class="hl-type">u32</span>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">f1</span> = <span class="hl-title function_ invoke__">fib</span>(n - <span class="hl-number">1</span>);</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">f2</span> = <span class="hl-title function_ invoke__">fib</span>(n - <span class="hl-number">2</span>);</code>
<code>    <span class="hl-keyword">return</span> f1 + f2;</code>
<code>}</code></pre>

</figure>
<p><span>Note that there</span>&rsquo;<span>s no base case, because L doesn</span>&rsquo;<span>t have syntax for </span><code>if</code><span>.</span>
<span>Here</span>&rsquo;<span>s the syntax it does have, as an </span><a href="https://rust-analyzer.github.io/blog/2020/10/24/introducing-ungrammar.html"><span>ungrammar</span></a><span>:</span></p>

<figure class="code-block">


<pre><code><span class="hl-literal">File</span> = Fn*</code>
<code></code>
<code><span class="hl-literal">Fn</span> = <span class="hl-string">&#x27;fn&#x27;</span> <span class="hl-string">&#x27;name&#x27;</span> ParamList (<span class="hl-string">&#x27;-&gt;&#x27;</span> TypeExpr)? Block</code>
<code></code>
<code><span class="hl-literal">ParamList</span> = <span class="hl-string">&#x27;(&#x27;</span> Param* <span class="hl-string">&#x27;)&#x27;</span></code>
<code><span class="hl-literal">Param</span> = <span class="hl-string">&#x27;name&#x27;</span> <span class="hl-string">&#x27;:&#x27;</span> TypeExpr <span class="hl-string">&#x27;,&#x27;</span>?</code>
<code></code>
<code><span class="hl-literal">TypeExpr</span> = <span class="hl-string">&#x27;name&#x27;</span></code>
<code></code>
<code><span class="hl-literal">Block</span> = <span class="hl-string">&#x27;{&#x27;</span> Stmt* <span class="hl-string">&#x27;}&#x27;</span></code>
<code></code>
<code><span class="hl-literal">Stmt</span> =</code>
<code>  StmtExpr</code>
<code>| StmtLet</code>
<code>| StmtReturn</code>
<code></code>
<code><span class="hl-literal">StmtExpr</span> = Expr <span class="hl-string">&#x27;;&#x27;</span></code>
<code><span class="hl-literal">StmtLet</span> = <span class="hl-string">&#x27;let&#x27;</span> <span class="hl-string">&#x27;name&#x27;</span> <span class="hl-string">&#x27;=&#x27;</span> Expr <span class="hl-string">&#x27;;&#x27;</span></code>
<code><span class="hl-literal">StmtReturn</span> = <span class="hl-string">&#x27;return&#x27;</span> Expr <span class="hl-string">&#x27;;&#x27;</span></code>
<code></code>
<code><span class="hl-literal">Expr</span> =</code>
<code>  ExprLiteral</code>
<code>| ExprName</code>
<code>| ExprParen</code>
<code>| ExprBinary</code>
<code>| ExprCall</code>
<code></code>
<code><span class="hl-literal">ExprLiteral</span> = <span class="hl-string">&#x27;int&#x27;</span> | <span class="hl-string">&#x27;true&#x27;</span> | <span class="hl-string">&#x27;false&#x27;</span></code>
<code><span class="hl-literal">ExprName</span> = <span class="hl-string">&#x27;name&#x27;</span></code>
<code><span class="hl-literal">ExprParen</span> = <span class="hl-string">&#x27;(&#x27;</span> Expr <span class="hl-string">&#x27;)&#x27;</span></code>
<code><span class="hl-literal">ExprBinary</span> = Expr (<span class="hl-string">&#x27;+&#x27;</span> | <span class="hl-string">&#x27;-&#x27;</span> | <span class="hl-string">&#x27;*&#x27;</span> | <span class="hl-string">&#x27;/&#x27;</span>) Expr</code>
<code><span class="hl-literal">ExprCall</span> = Expr ArgList</code>
<code></code>
<code><span class="hl-literal">ArgList</span> = <span class="hl-string">&#x27;(&#x27;</span> Arg* <span class="hl-string">&#x27;)&#x27;</span></code>
<code><span class="hl-literal">Arg</span> = Expr <span class="hl-string">&#x27;,&#x27;</span>?</code></pre>

</figure>
<p><span>The meta syntax here is similar to BNF, with two important differences:</span></p>
<ul>
<li>
<span>the notation is better specified and more familiar (recursive regular expressions),</span>
</li>
<li>
<span>it describes syntax </span><em><span>trees</span></em><span>, rather than strings (</span><em><span>sequences</span></em><span> of tokens).</span>
</li>
</ul>
<p><span>Single quotes signify terminals: </span><code>'fn'</code><span> and </span><code>'return'</code><span> are keywords, </span><code>'name'</code><span> stands for any identifier token, like </span><code>foo</code><span>, and </span><code>'('</code><span> is punctuation.</span>
<span>Unquoted names are non-terminals. For example, </span><code>x: i32,</code><span> would be an example of </span><code>Param</code><span>.</span>
<span>Unquoted punctuation are meta symbols of ungrammar itself, semantics identical to regular expressions. Zero or more repetition is </span><code>*</code><span>, zero or one is </span><code>?</code><span>, </span><code>|</code><span> is alternation and </span><code>()</code><span> are used for grouping.</span></p>
<p><span>The grammar doesn</span>&rsquo;<span>t nail the syntax precisely. For example, the rule for </span><code>Param</code><span>, </span><span class="display"><code>Param = 'name' ':' Type ','?</code><span> ,</span></span><span> says that </span><code>Param</code><span> syntax node has an optional comma, but there</span>&rsquo;<span>s nothing in the above </span><code>ungrammar</code><span> specifying whether the trailing commas are allowed.</span></p>
<p><span>Overall, </span><code>L</code><span> has very little to it </span>&mdash;<span> a program is a series of function declarations, each function has a body which is a sequence of statements, the set of expressions is spartan, not even an </span><code>if</code><span>. Still, it</span>&rsquo;<span>ll take us some time to parse all that.</span>
<span>But you can already try the end result in the text-box below.</span>
<span>The syntax tree is updated automatically on typing.</span>
<span>Do make mistakes to see how a partial tree is recovered.</span></p>
<aside id="playground" style="min-height: 400px; min-width: 400px; ; display: flex; flex-direction: row;">
<textarea class="input"  style="height: 400px; width: 50%; margin: 2px; padding: 2px; resize: none;">
fn fib_rec(f1: u32,

fn fib(n: u32) -> u32 {
  fib_rec(1, 1, n)
}
</textarea>
<textarea class="output" style="height: 400px; width: 50%; margin: 2px; padding: 2px; resize: none;" readonly=true>
</textarea>
</aside>
</section>
<section id="Designing-the-Tree">

    <h2>
    <a href="#Designing-the-Tree"><span>Designing the Tree</span> </a>
    </h2>
<p><span>A traditional AST for L might look roughly like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">struct</span> <span class="hl-title class_">File</span> {</code>
<code>  functions: <span class="hl-type">Vec</span>&lt;Function&gt;</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">Function</span> {</code>
<code>  name: <span class="hl-type">String</span>,</code>
<code>  params: <span class="hl-type">Vec</span>&lt;Param&gt;,</code>
<code>  return_type: <span class="hl-type">Option</span>&lt;TypeExpr&gt;,</code>
<code>  block: Block,</code>
<code>}</code></pre>

</figure>
<p><span>Extending this structure to be resilient is non-trivial. There are two problems: trivia and errors.</span></p>
<p><span>For resilient parsing, we want the AST to contain every detail about the source text.</span>
<span>We actually don</span>&rsquo;<span>t want to use an </span><em><span>abstract</span></em><span> syntax tree, and need a </span><em><span>concrete</span></em><span> one.</span>
<span>In a traditional AST, the tree structure is rigidly defined </span>&mdash;<span> any syntax node has a fixed number of children.</span>
<span>But there can be any number of comments and whitespace anywhere in the tree, and making space for them in the structure requires some fiddly data manipulation.</span>
<span>Similarly, errors (e.g., unexpected tokens), can appear anywhere in the tree.</span></p>
<p><span>One trick to handle these in the AST paradigm is to attach trivia and error tokens to other tokens.</span>
<span>That is, for something like</span>
<span class="display"><code>fn /* name of the function -&gt; */ f() {}</code><span> ,</span></span>
<span>the </span><code>fn</code><span> and </span><code>f</code><span> tokens would be explicit parts of the AST, while the comment and surrounding whitespace would belong to the collection of trivia tokens hanging off the </span><code>fn</code><span> token.</span></p>
<p><span>One complication here is that it</span>&rsquo;<span>s not always just tokens that can appear anywhere, sometimes you can have full trees like that.</span>
<span>For example, comments might support markdown syntax, and you might actually want to parse that properly (e.g., to resolve links to declarations).</span>
<span>Syntax errors can also span whole subtrees.</span>
<span>For example, when parsing </span><code>pub(crate) nope</code><span> in Rust, it would be smart to parse </span><code>pub(crate)</code><span> as a visibility modifier, and nest it into a bigger </span><code>Error</code><span> node.</span></p>
<p><span>SwiftSyntax meticulously adds error placeholders between any two fields of an AST node, giving rise to</span>
<span class="display"><code>unexpectedBetweenModifiersAndDeinitKeyword</code></span>
<span>and such (</span><a href="https://github.com/apple/swift-syntax/blob/66450960b1ed88b842d63f7a38254aaba08bbd4d/Sources/SwiftSyntax/generated/syntaxNodes/SyntaxDeclNodes.swift#L1368"><span>source</span></a><span>, </span><a href="https://swiftpackageindex.com/apple/swift-syntax/508.0.1/documentation/swiftsyntax/classdeclsyntax#instance-properties"><span>docs</span></a><span>).</span></p>
<p><span>An alternative approach, used by IntelliJ and rust-analyzer, is to treat the syntax tree as a somewhat dynamically-typed data structure:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">enum</span> <span class="hl-title class_">TokenKind</span> {</code>
<code>  ErrorToken, LParen, RParen, <span class="hl-built_in">Eq</span>,</code>
<code>  ...</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">Token</span> {</code>
<code>  kind: TokenKind,</code>
<code>  text: <span class="hl-type">String</span>,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">enum</span> <span class="hl-title class_">TreeKind</span> {</code>
<code>  ErrorTree, File, <span class="hl-built_in">Fn</span>, Param,</code>
<code>  ...</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">Tree</span> {</code>
<code>  kind: TreeKind,</code>
<code>  children: <span class="hl-type">Vec</span>&lt;Child&gt;,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">enum</span> <span class="hl-title class_">Child</span> {</code>
<code>  <span class="hl-title function_ invoke__">Token</span>(Token),</code>
<code>  <span class="hl-title function_ invoke__">Tree</span>(Tree),</code>
<code>}</code></pre>

</figure>
<p><span>This structure does not enforce any constraints on the shape of the syntax tree at all, and so it naturally accommodates errors anywhere.</span>
<span>It is possible to layer a well-typed API on top of this dynamic foundation.</span>
<span>An extra benefit of this representation is that you can use the same tree </span><em><span>type</span></em><span> for different languages; this is a requirement for universal tools.</span></p>
<p><span>Discussing specifics of syntax tree representation goes beyond this article, as the topic is vast and lacks a clear winning solution.</span>
<span>To learn about it, take a look at Roslyn, SwiftSyntax, rowan and IntelliJ.</span></p>
<p><span>To simplify things, we</span>&rsquo;<span>ll ignore comments and whitespace, though you</span>&rsquo;<span>ll absolutely want those in a real implementation.</span>
<span>One approach would be to do the parsing without comments, like we do here, and then attach comments to the nodes in a separate pass.</span>
<span>Attaching comments needs some heuristics </span>&mdash;<span> for example, non-doc comments generally want to be a part of the following syntax node.</span></p>
<p><span>Another design choice is handling of error messages.</span>
<span>One approach is to treat error messages as properties of the syntax tree itself, by either inferring them from the tree structure, or just storing them inline.</span>
<span>Alternatively, errors can be considered to be a side-effect of the parsing process (that way, trees constructed manually during, eg, refactors, won</span>&rsquo;<span>t carry any error messages, even if they are invalid).</span></p>
<p><span>Here</span>&rsquo;<span>s the full set of token and tree kinds for our language L:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">enum</span> <span class="hl-title class_">TokenKind</span> {</code>
<code>  ErrorToken, Eof,</code>
<code></code>
<code>  LParen, RParen, LCurly, RCurly,</code>
<code>  <span class="hl-built_in">Eq</span>, Semi, Comma, Colon, Arrow,</code>
<code>  Plus, Minus, Star, Slash,</code>
<code></code>
<code>  FnKeyword, LetKeyword, ReturnKeyword,</code>
<code>  TrueKeyword, FalseKeyword,</code>
<code></code>
<code>  Name, Int,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">enum</span> <span class="hl-title class_">TreeKind</span> {</code>
<code>  ErrorTree,</code>
<code>  File, <span class="hl-built_in">Fn</span>, TypeExpr,</code>
<code>  ParamList, Param,</code>
<code>  Block,</code>
<code>  StmtLet, StmtReturn, StmtExpr,</code>
<code>  ExprLiteral, ExprName, ExprParen,</code>
<code>  ExprBinary, ExprCall,</code>
<code>  ArgList, Arg,</code>
<code>}</code></pre>

</figure>
<p><span>Things to note:</span></p>
<ul>
<li>
<span>explicit </span><code>Error</code><span> kinds;</span>
</li>
<li>
<span>no whitespace or comments, as an unrealistic simplification;</span>
</li>
<li>
<code>Eof</code><span> virtual token simplifies parsing, removing the need to handle </span><code>Option&lt;Token&gt;</code><span>;</span>
</li>
<li>
<span>punctuators are named after what they are, rather than after what they usually mean: </span><code>Star</code><span>, rather than </span><code>Mult</code><span>;</span>
</li>
<li>
<span>a good set of name for various kinds of braces is </span><span class="display"><code>{L,R}{Paren,Curly,Brack,Angle}</code><span>.</span></span>
</li>
</ul>
</section>
<section id="Lexer">

    <h2>
    <a href="#Lexer"><span>Lexer</span> </a>
    </h2>
<p><span>Won</span>&rsquo;<span>t be covering lexer here, let</span>&rsquo;<span>s just say we have </span><span class="display"><code>fn lex(text: &amp;str) -&gt; Vec&lt;Token&gt;</code><span>,</span></span><span> function. Two points worth mentioning:</span></p>
<ul>
<li>
<span>Lexer itself should be resilient, but that</span>&rsquo;<span>s easy </span>&mdash;<span> produce an </span><code>Error</code><span> token for anything which isn</span>&rsquo;<span>t a valid token.</span>
</li>
<li>
<span>Writing lexer by hand is somewhat tedious, but is very simple relative to everything else.</span>
<span>If you are stuck in an analysis-paralysis picking a lexer generator, consider cutting the Gordian knot and hand-writing.</span>
</li>
</ul>
</section>
<section id="Parser">

    <h2>
    <a href="#Parser"><span>Parser</span> </a>
    </h2>
<p><span>With homogenous syntax trees, the task of parsing admits an elegant formalization </span>&mdash;<span> we want to insert extra parenthesis into a stream of tokens.</span></p>

<figure class="code-block">


<pre><code>+-Fun</code>
<code>|      +-Param</code>
<code>|      |</code>
<code>[fn f( [x: Int] ) {}]</code>
<code>     |            |</code>
<code>     |            +-Block</code>
<code>     +-ParamList</code></pre>

</figure>
<p><span>Note how the sequence of tokens with extra parenthesis is still a flat sequence.</span>
<span>The parsing will be two-phase:</span></p>
<ul>
<li>
<span>in the first phase, the parser emits a flat list of events,</span>
</li>
<li>
<span>in the second phase, the list is converted to a tree.</span>
</li>
</ul>
<p><span>Here</span>&rsquo;<span>s the basic setup for the parser:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">enum</span> <span class="hl-title class_">Event</span> {</code>
<code>  Open { kind: TreeKind }, <i class="callout" data-value="2"></i></code>
<code>  Close,</code>
<code>  Advance,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">MarkOpened</span> {</code>
<code>  index: <span class="hl-type">usize</span>,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">Parser</span> {</code>
<code>  tokens: <span class="hl-type">Vec</span>&lt;Token&gt;,</code>
<code>  pos: <span class="hl-type">usize</span>,</code>
<code>  fuel: Cell&lt;<span class="hl-type">u32</span>&gt;, <i class="callout" data-value="4"></i></code>
<code>  events: <span class="hl-type">Vec</span>&lt;Event&gt;,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">impl</span> <span class="hl-title class_">Parser</span> {</code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">open</span>(&amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>) <span class="hl-punctuation">-&gt;</span> MarkOpened { <i class="callout" data-value="1"></i></code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">mark</span> = MarkOpened { index: <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">len</span>() };</code>
<code>    <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">push</span>(Event::Open { kind: TreeKind::ErrorTree });</code>
<code>    mark</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">close</span>(  <i class="callout" data-value="1"></i></code>
<code>    &amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>,</code>
<code>    m: MarkOpened,</code>
<code>    kind: TreeKind, <i class="callout" data-value="2"></i></code>
<code>  ) {</code>
<code>    <span class="hl-keyword">self</span>.events[m.index] = Event::Open { kind };</code>
<code>    <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">push</span>(Event::Close);</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">advance</span>(&amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>) { <i class="callout" data-value="1"></i></code>
<code>    <span class="hl-built_in">assert!</span>(!<span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">eof</span>());</code>
<code>    <span class="hl-keyword">self</span>.fuel.<span class="hl-title function_ invoke__">set</span>(<span class="hl-number">256</span>); <i class="callout" data-value="4"></i></code>
<code>    <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">push</span>(Event::Advance);</code>
<code>    <span class="hl-keyword">self</span>.pos += <span class="hl-number">1</span>;</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">eof</span>(&amp;<span class="hl-keyword">self</span>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">bool</span> {</code>
<code>    <span class="hl-keyword">self</span>.pos == <span class="hl-keyword">self</span>.tokens.<span class="hl-title function_ invoke__">len</span>()</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">nth</span>(&amp;<span class="hl-keyword">self</span>, lookahead: <span class="hl-type">usize</span>) <span class="hl-punctuation">-&gt;</span> TokenKind { <i class="callout" data-value="3"></i></code>
<code>    <span class="hl-keyword">if</span> <span class="hl-keyword">self</span>.fuel.<span class="hl-title function_ invoke__">get</span>() == <span class="hl-number">0</span> { <i class="callout" data-value="4"></i></code>
<code>      <span class="hl-built_in">panic!</span>(<span class="hl-string">&quot;parser is stuck&quot;</span>)</code>
<code>    }</code>
<code>    <span class="hl-keyword">self</span>.fuel.<span class="hl-title function_ invoke__">set</span>(<span class="hl-keyword">self</span>.fuel.<span class="hl-title function_ invoke__">get</span>() - <span class="hl-number">1</span>);</code>
<code>    <span class="hl-keyword">self</span>.tokens.<span class="hl-title function_ invoke__">get</span>(<span class="hl-keyword">self</span>.pos + lookahead)</code>
<code>      .<span class="hl-title function_ invoke__">map_or</span>(TokenKind::Eof, |it| it.kind)</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">at</span>(&amp;<span class="hl-keyword">self</span>, kind: TokenKind) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">bool</span> { <i class="callout" data-value="3"></i></code>
<code>    <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">nth</span>(<span class="hl-number">0</span>) == kind</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">eat</span>(&amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>, kind: TokenKind) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">bool</span> { <i class="callout" data-value="3"></i></code>
<code>    <span class="hl-keyword">if</span> <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">at</span>(kind) {</code>
<code>      <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>      <span class="hl-literal">true</span></code>
<code>    } <span class="hl-keyword">else</span> {</code>
<code>      <span class="hl-literal">false</span></code>
<code>    }</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">expect</span>(&amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>, kind: TokenKind) {</code>
<code>    <span class="hl-keyword">if</span> <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">eat</span>(kind) {</code>
<code>      <span class="hl-keyword">return</span>;</code>
<code>    }</code>
<code>    <span class="hl-comment">// <span class="hl-doctag">TODO:</span> Error reporting.</span></code>
<code>    eprintln!(<span class="hl-string">&quot;expected {kind:?}&quot;</span>);</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">advance_with_error</span>(&amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>, error: &amp;<span class="hl-type">str</span>) {</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">open</span>();</code>
<code>    <span class="hl-comment">// <span class="hl-doctag">TODO:</span> Error reporting.</span></code>
<code>    eprintln!(<span class="hl-string">&quot;{error}&quot;</span>);</code>
<code>    <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>    <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">close</span>(m, ErrorTree);</code>
<code>  }</code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<p><code>open</code><span>, </span><code>advance</code><span>, and </span><code>close</code><span> form the basis for constructing the stream of events.</span></p>
</li>
<li>
<p><span>Note how </span><code>kind</code><span> is stored in the </span><code>Open</code><span> event, but is supplied with the </span><code>close</code><span> method.</span>
<span>This is required for flexibility </span>&mdash;<span> sometimes it</span>&rsquo;<span>s possible to decide on the type of syntax node only after it is parsed.</span>
<span>The way this works is that the </span><code>open</code><span> method returns a </span><code>Mark</code><span> which is subsequently passed to </span><code>close</code><span> to modify the corresponding </span><code>Open</code><span> event.</span></p>
</li>
<li>
<p><span>There</span>&rsquo;<span>s a set of short, convenient methods to navigate through the sequence of tokens:</span></p>
<ul>
<li>
<code>nth</code><span> is the lookahead method. Note how it doesn</span>&rsquo;<span>t return an </span><code>Option</code><span>, and uses </span><code>Eof</code><span> special value for </span>&ldquo;<span>out of bounds</span>&rdquo;<span> indexes.</span>
<span>This simplifies the call-site, </span>&ldquo;<span>no more tokens</span>&rdquo;<span> and </span>&ldquo;<span>token of a wrong kind</span>&rdquo;<span> are always handled the same.</span>
</li>
<li>
<code>at</code><span> is a convenient specialization to check for a specific next token.</span>
</li>
<li>
<code>eat</code><span> is </span><code>at</code><span> combined with consuming the next token.</span>
</li>
<li>
<code>expect</code><span> is </span><code>eat</code><span> combined with error reporting.</span>
</li>
</ul>
<p><span>These methods are not a very orthogonal basis, but they are a convenience basis for parsing.</span>
<span>Finally, </span><code>advance_with_error</code><span> advanced over any token, but also wraps it into an error node.</span></p>
</li>
<li>
<p><span>When writing parsers by hand, it</span>&rsquo;<span>s very easy to accidentally write the code which loops or recurses forever.</span>
<span>To simplify debugging, it</span>&rsquo;<span>s helpful to add an explicit notion of </span>&ldquo;<span>fuel</span>&rdquo;<span>, which is replenished every time the parser makes progress,</span>
<span>and is spent every time it does not.</span></p>
</li>
</ol>
<p><span>The function to transform a flat list of events into a tree is a bit involved.</span>
<span>It juggles three things: an iterator of events, an iterator of tokens, and a stack of partially constructed nodes (we expect the stack to contain just one node at the end).</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">impl</span> <span class="hl-title class_">Parser</span> {</code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">build_tree</span>(<span class="hl-keyword">self</span>) <span class="hl-punctuation">-&gt;</span> Tree {</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">tokens</span> = <span class="hl-keyword">self</span>.tokens.<span class="hl-title function_ invoke__">into_iter</span>();</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">events</span> = <span class="hl-keyword">self</span>.events;</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">stack</span> = <span class="hl-type">Vec</span>::<span class="hl-title function_ invoke__">new</span>();</code>
<code></code>
<code>    <span class="hl-comment">// Special case: pop the last `Close` event to ensure</span></code>
<code>    <span class="hl-comment">// that the stack is non-empty inside the loop.</span></code>
<code>    <span class="hl-built_in">assert!</span>(matches!(events.<span class="hl-title function_ invoke__">pop</span>(), <span class="hl-title function_ invoke__">Some</span>(Event::Close)));</code>
<code></code>
<code>    <span class="hl-keyword">for</span> <span class="hl-variable">event</span> <span class="hl-keyword">in</span> events {</code>
<code>      <span class="hl-keyword">match</span> event {</code>
<code>        <span class="hl-comment">// Starting a new node; just push an empty tree to the stack.</span></code>
<code>        Event::Open { kind } =&gt; {</code>
<code>          stack.<span class="hl-title function_ invoke__">push</span>(Tree { kind, children: <span class="hl-type">Vec</span>::<span class="hl-title function_ invoke__">new</span>() })</code>
<code>        }</code>
<code></code>
<code>        <span class="hl-comment">// A tree is done.</span></code>
<code>        <span class="hl-comment">// Pop it off the stack and append to a new current tree.</span></code>
<code>        Event::Close =&gt; {</code>
<code>          <span class="hl-keyword">let</span> <span class="hl-variable">tree</span> = stack.<span class="hl-title function_ invoke__">pop</span>().<span class="hl-title function_ invoke__">unwrap</span>();</code>
<code>          stack</code>
<code>            .<span class="hl-title function_ invoke__">last_mut</span>()</code>
<code>            <span class="hl-comment">// If we don&#x27;t pop the last `Close` before this loop,</span></code>
<code>            <span class="hl-comment">// this unwrap would trigger for it.</span></code>
<code>            .<span class="hl-title function_ invoke__">unwrap</span>()</code>
<code>            .children</code>
<code>            .<span class="hl-title function_ invoke__">push</span>(Child::<span class="hl-title function_ invoke__">Tree</span>(tree));</code>
<code>        }</code>
<code></code>
<code>        <span class="hl-comment">// Consume a token and append it to the current tree</span></code>
<code>        Event::Advance =&gt; {</code>
<code>          <span class="hl-keyword">let</span> <span class="hl-variable">token</span> = tokens.<span class="hl-title function_ invoke__">next</span>().<span class="hl-title function_ invoke__">unwrap</span>();</code>
<code>          stack</code>
<code>            .<span class="hl-title function_ invoke__">last_mut</span>()</code>
<code>            .<span class="hl-title function_ invoke__">unwrap</span>()</code>
<code>            .children</code>
<code>            .<span class="hl-title function_ invoke__">push</span>(Child::<span class="hl-title function_ invoke__">Token</span>(token));</code>
<code>        }</code>
<code>      }</code>
<code>    }</code>
<code></code>
<code>    <span class="hl-comment">// Our parser will guarantee that all the trees are closed</span></code>
<code>    <span class="hl-comment">// and cover the entirety of tokens.</span></code>
<code>    <span class="hl-built_in">assert!</span>(stack.<span class="hl-title function_ invoke__">len</span>() == <span class="hl-number">1</span>);</code>
<code>    <span class="hl-built_in">assert!</span>(tokens.<span class="hl-title function_ invoke__">next</span>().<span class="hl-title function_ invoke__">is_none</span>());</code>
<code></code>
<code>    stack.<span class="hl-title function_ invoke__">pop</span>().<span class="hl-title function_ invoke__">unwrap</span>()</code>
<code>  }</code>
<code>}</code></pre>

</figure>
</section>
<section id="Grammar">

    <h2>
    <a href="#Grammar"><span>Grammar</span> </a>
    </h2>
<p><span>We are finally getting to the actual topic of resilient parser.</span>
<span>Now we will write a full grammar for L as a sequence of functions.</span>
<span>Usually both atomic parser operations, like </span><code>fn advance</code><span>, and grammar productions, like </span><code>fn parse_fn</code><span> are implemented as methods on the </span><code>Parser</code><span> struct.</span>
<span>I prefer to separate the two and to use free functions for the latter category, as the code is a bit more readable that way.</span></p>
<p><span>Let</span>&rsquo;<span>s start with parsing the top level.</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">use</span> TokenKind::*;</code>
<code><span class="hl-keyword">use</span> TreeKind::*;</code>
<code></code>
<code><span class="hl-comment">// File = Fn*</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">file</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>(); <i class="callout" data-value="1"></i></code>
<code></code>
<code>  <span class="hl-keyword">while</span> !p.<span class="hl-title function_ invoke__">eof</span>() { <i class="callout" data-value="2"></i></code>
<code>    <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at</span>(FnKeyword) {</code>
<code>      <span class="hl-title function_ invoke__">func</span>(p)</code>
<code>    } <span class="hl-keyword">else</span> {</code>
<code>      p.<span class="hl-title function_ invoke__">advance_with_error</span>(<span class="hl-string">&quot;expected a function&quot;</span>); <i class="callout" data-value="3"></i></code>
<code>    }</code>
<code>  }</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, File);  <i class="callout" data-value="1"></i></code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<p><span>Wrap the whole thing into a </span><code>File</code><span> node.</span></p>
</li>
<li>
<p><span>Use the </span><code>while</code><span> loop to parse a file as a series of functions.</span>
<span>Importantly, the entirety of the file is parsed; we break out of the loop only when the eof is reached.</span></p>
</li>
<li>
<p><span>To not get stuck in this loop, it</span>&rsquo;<span>s crucial that every iteration consumes at least one token.</span>
<span>If the token is </span><code>fn</code><span>, we</span>&rsquo;<span>ll parse at least a part of a function.</span>
<span>Otherwise, we consume the token and wrap it into an error node.</span></p>
</li>
</ol>
<p><span>Lets parse functions now:</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// Fn = &#x27;fn&#x27; &#x27;name&#x27; ParamList (&#x27;-&gt;&#x27; TypeExpr)? Block</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">func</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(FnKeyword)); <i class="callout" data-value="1"></i></code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>(); <i class="callout" data-value="2"></i></code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(FnKeyword);</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Name);</code>
<code>  <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at</span>(LParen) { <i class="callout" data-value="3"></i></code>
<code>    <span class="hl-title function_ invoke__">param_list</span>(p);</code>
<code>  }</code>
<code>  <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">eat</span>(Arrow) {</code>
<code>    <span class="hl-title function_ invoke__">type_expr</span>(p);</code>
<code>  }</code>
<code>  <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at</span>(LCurly) { <i class="callout" data-value="3"></i></code>
<code>    <span class="hl-title function_ invoke__">block</span>(p);</code>
<code>  }</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, <span class="hl-built_in">Fn</span>); <i class="callout" data-value="2"></i></code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<p><span>When parsing a function, we assert that the current token is </span><code>fn</code><span>.</span>
<span>There</span>&rsquo;<span>s some duplication with the </span><span class="display"><code>if p.at(FnKeyword)</code><span> ,</span></span><span> check at the call-site, but this duplication actually helps readability.</span></p>
</li>
<li>
<p><span>Again, we surround the body of the function with </span><code>open</code><span>/</span><code>close</code><span> pair.</span></p>
</li>
<li>
<p><span>Although parameter list and function body are mandatory, we precede them with an </span><code>at</code><span> check.</span>
<span>We can still report the syntax error by analyzing the structure of the syntax tree (or we can report it as a side effect of parsing in the </span><code>else</code><span> branch if we want).</span>
<span>It wouldn</span>&rsquo;<span>t be wrong to just remove the </span><code>if</code><span> altogether and try to parse </span><code>param_list</code><span> unconditionally, but the </span><code>if</code><span> helps with reducing cascading errors.</span></p>
</li>
</ol>
<p><span>Now, the list of parameters:</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// ParamList = &#x27;(&#x27; Param* &#x27;)&#x27;</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">param_list</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(LParen));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(LParen); <i class="callout" data-value="1"></i></code>
<code>  <span class="hl-keyword">while</span> !p.<span class="hl-title function_ invoke__">at</span>(RParen) &amp;&amp; !p.<span class="hl-title function_ invoke__">eof</span>() { <i class="callout" data-value="2"></i></code>
<code>    <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at</span>(Name) { <i class="callout" data-value="3"></i></code>
<code>      <span class="hl-title function_ invoke__">param</span>(p);</code>
<code>    } <span class="hl-keyword">else</span> {</code>
<code>      <span class="hl-keyword">break</span>; <i class="callout" data-value="3"></i></code>
<code>    }</code>
<code>  }</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(RParen); <i class="callout" data-value="1"></i></code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, ParamList);</code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<span>Inside, we have a standard code shape for parsing a bracketed list.</span>
<span>It can be extracted into a high-order function, but typing out the code manually is not a problem either.</span>
<span>This bit of code starts and ends with consuming the corresponding parenthesis.</span>
</li>
<li>
<span>In the happy case, we loop until the closing parenthesis.</span>
<span>However, it could also be the case that there</span>&rsquo;<span>s no closing parenthesis at all, so we add an </span><code>eof</code><span> condition as well.</span>
<span>Generally, every loop we write would have </span><code>&amp;&amp; !p.eof()</code><span> tackled on.</span>
</li>
<li>
<span>As with any loop, we need to ensure that each iteration consumes at least one token to not get stuck.</span>
<span>If the current token is an identifier, everything is ok, as we</span>&rsquo;<span>ll parse at least some part of the parameter.</span>
</li>
</ol>
<p><span>Parsing parameter is almost nothing new at this point:</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// Param = &#x27;name&#x27; &#x27;:&#x27; TypeExpr &#x27;,&#x27;?</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">param</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(Name));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Name);</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Colon);</code>
<code>  <span class="hl-title function_ invoke__">type_expr</span>(p);</code>
<code>  <span class="hl-keyword">if</span> !p.<span class="hl-title function_ invoke__">at</span>(RParen) { <i class="callout" data-value="1"></i></code>
<code>    p.<span class="hl-title function_ invoke__">expect</span>(Comma);</code>
<code>  }</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, Param);</code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<span>This is the only interesting bit.</span>
<span>To parse a comma-separated list of parameters with a trailing comma, it</span>&rsquo;<span>s enough to check if the following token after parameter is </span><code>)</code><span>.</span>
<span>This correctly handles all three cases:</span>
<ul>
<li>
<span>if the next token is </span><code>)</code><span>, we are at the end of the list, and no comma is required;</span>
</li>
<li>
<span>if the next token is </span><code>,</code><span>, we correctly advance past it;</span>
</li>
<li>
<span>finally, if the next token is anything else, then it</span>&rsquo;<span>s not a </span><code>)</code><span>, so we are not at the last element of the list and correctly emit an error.</span>
</li>
</ul>
</li>
</ol>
<p><span>Parsing types is trivial:</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// TypeExpr = &#x27;name&#x27;</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">type_expr</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Name);</code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, TypeExpr);</code>
<code>}</code></pre>

</figure>
<p><span>The notable aspect here is naming.</span>
<span>The production is deliberately named </span><code>TypeExpr</code><span>, rather than </span><code>Type</code><span>, to avoid confusion down the line.</span>
<span>Consider </span><span class="display"><code>fib(92)</code><span> .</span></span>
<span>It is an </span><em><span>expression</span></em><span>, which evaluates to a </span><em><span>value</span></em><span>.</span>
<span>The same thing happens with types.</span>
<span>For example, </span><span class="display"><code>Foo&lt;Int&gt;</code></span><span> is not a type yet, it</span>&rsquo;<span>s an expression which can be </span>&ldquo;<span>evaluated</span>&rdquo;<span> (at compile time) to a type (if </span><code>Foo</code><span> is a type alias, the result might be something like </span><code>Pair&lt;Int, Int&gt;</code><span>).</span></p>
<p><span>Parsing a block gets a bit more involved:</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// Block = &#x27;{&#x27; Stmt* &#x27;}&#x27;</span></code>
<code><span class="hl-comment">//</span></code>
<code><span class="hl-comment">// Stmt =</span></code>
<code><span class="hl-comment">//   StmtLet</span></code>
<code><span class="hl-comment">// | StmtReturn</span></code>
<code><span class="hl-comment">// | StmtExpr</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">block</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(LCurly));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(LCurly);</code>
<code>  <span class="hl-keyword">while</span> !p.<span class="hl-title function_ invoke__">at</span>(RCurly) &amp;&amp; !p.<span class="hl-title function_ invoke__">eof</span>() {</code>
<code>    <span class="hl-keyword">match</span> p.<span class="hl-title function_ invoke__">nth</span>(<span class="hl-number">0</span>) {</code>
<code>      LetKeyword =&gt; <span class="hl-title function_ invoke__">stmt_let</span>(p),</code>
<code>      ReturnKeyword =&gt; <span class="hl-title function_ invoke__">stmt_return</span>(p),</code>
<code>      _ =&gt; <span class="hl-title function_ invoke__">stmt_expr</span>(p),</code>
<code>    }</code>
<code>  }</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(RCurly);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, Block);</code>
<code>}</code></pre>

</figure>
<p><span>Block can contain many different kinds of statements, so we branch on the first token in the loop</span>&rsquo;<span>s body.</span>
<span>As usual, we need to maintain an invariant that the body consumes at least one token.</span>
<span>For </span><code>let</code><span> and </span><code>return</code><span> statements that</span>&rsquo;<span>s easy, they consume the fixed first token.</span>
<span>For the expression statement (things like </span><code>1 + 1;</code><span>) it gets more interesting, as an expression can start with many different tokens.</span>
<span>For the time being, we</span>&rsquo;<span>ll just kick the can down the road and require </span><code>stmt_expr</code><span> to deal with it (that is, to guarantee that at least one token is consumed).</span></p>
<p><span>Statements themselves are straightforward:</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// StmtLet = &#x27;let&#x27; &#x27;name&#x27; &#x27;=&#x27; Expr &#x27;;&#x27;</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">stmt_let</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(LetKeyword));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(LetKeyword);</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Name);</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(<span class="hl-built_in">Eq</span>);</code>
<code>  <span class="hl-title function_ invoke__">expr</span>(p);</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Semi);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, StmtLet);</code>
<code>}</code>
<code></code>
<code><span class="hl-comment">// StmtReturn = &#x27;return&#x27; Expr &#x27;;&#x27;</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">stmt_return</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(ReturnKeyword));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(ReturnKeyword);</code>
<code>  <span class="hl-title function_ invoke__">expr</span>(p);</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Semi);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, StmtReturn);</code>
<code>}</code>
<code></code>
<code><span class="hl-comment">// StmtExpr = Expr &#x27;;&#x27;</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">stmt_expr</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  <span class="hl-title function_ invoke__">expr</span>(p);</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(Semi);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, StmtExpr);</code>
<code>}</code></pre>

</figure>
<p><span>Again, for </span><code>stmt_expr</code><span>, we push </span>&ldquo;<span>must consume a token</span>&rdquo;<span> invariant onto </span><code>expr</code><span>.</span></p>
<p><span>Expressions are tricky.</span>
<span>They always are.</span>
<span>For starters, let</span>&rsquo;<span>s handle just the clearly-delimited cases, like literals and parenthesis:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">expr</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-title function_ invoke__">expr_delimited</span>(p)</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">expr_delimited</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code>  <span class="hl-keyword">match</span> p.<span class="hl-title function_ invoke__">nth</span>(<span class="hl-number">0</span>) {</code>
<code>    <span class="hl-comment">// ExprLiteral = &#x27;int&#x27; | &#x27;true&#x27; | &#x27;false&#x27;</span></code>
<code>    Int | TrueKeyword | FalseKeyword =&gt; {</code>
<code>      p.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>      p.<span class="hl-title function_ invoke__">close</span>(m, ExprLiteral)</code>
<code>    }</code>
<code></code>
<code>    <span class="hl-comment">// ExprName = &#x27;name&#x27;</span></code>
<code>    Name =&gt; {</code>
<code>      p.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>      p.<span class="hl-title function_ invoke__">close</span>(m, ExprName)</code>
<code>    }</code>
<code></code>
<code>    <span class="hl-comment">// ExprParen   = &#x27;(&#x27; Expr &#x27;)&#x27;</span></code>
<code>    LParen =&gt; {</code>
<code>      p.<span class="hl-title function_ invoke__">expect</span>(LParen);</code>
<code>      <span class="hl-title function_ invoke__">expr</span>(p);</code>
<code>      p.<span class="hl-title function_ invoke__">expect</span>(RParen);</code>
<code>      p.<span class="hl-title function_ invoke__">close</span>(m, ExprParen)</code>
<code>    }</code>
<code></code>
<code>    _ =&gt; {</code>
<code>      <span class="hl-keyword">if</span> !p.<span class="hl-title function_ invoke__">eof</span>() {</code>
<code>        p.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>      }</code>
<code>      p.<span class="hl-title function_ invoke__">close</span>(m, ErrorTree)</code>
<code>    }</code>
<code>  }</code>
<code>}</code></pre>

</figure>
<p><span>In the catch-all arm, we take care to consume the token, to make sure that the statement loop in </span><code>block</code><span> can always make progress.</span></p>
<p><span>Next expression to handle would be </span><code>ExprCall</code><span>.</span>
<span>This requires some preparation.</span>
<span>Consider this example: </span><span class="display"><code>f(1)(2)</code><span> .</span></span></p>
<p><span>We want the following parenthesis structure here:</span></p>

<figure class="code-block">


<pre><code>+-ExprCall</code>
<code>|</code>
<code>|   +-ExprName</code>
<code>|   |       +-ArgList</code>
<code>|   |       |</code>
<code>[ [ [f](1) ](2) ]</code>
<code>  |    |</code>
<code>  |    +-ArgList</code>
<code>  |</code>
<code>  +-ExprCall</code></pre>

</figure>
<p><span>The problem is, when the parser is at </span><code>f</code><span>, it doesn</span>&rsquo;<span>t yet know how many </span><code>Open</code><span> events it should emit.</span></p>
<p><span>We solve the problem by adding an API to go back and inject a new </span><code>Open</code><span> event into the middle of existing events.</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">struct</span> <span class="hl-title class_">MarkOpened</span> {</code>
<code>  index: <span class="hl-type">usize</span>,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">MarkClosed</span> {</code>
<code>  index: <span class="hl-type">usize</span>,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">impl</span> <span class="hl-title class_">Parser</span> {</code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">open</span>(&amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>) <span class="hl-punctuation">-&gt;</span> MarkOpened {</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">mark</span> = MarkOpened { index: <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">len</span>() };</code>
<code>    <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">push</span>(Event::Open { kind: TreeKind::ErrorTree });</code>
<code>    mark</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">close</span>(</code>
<code>    &amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>,</code>
<code>    m: MarkOpened,</code>
<code>    kind: TreeKind,</code>
<code>  ) <span class="hl-punctuation">-&gt;</span> MarkClosed { <i class="callout" data-value="1"></i></code>
<code>    <span class="hl-keyword">self</span>.events[m.index] = Event::Open { kind };</code>
<code>    <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">push</span>(Event::Close);</code>
<code>    MarkClosed { index: m.index }</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">open_before</span>(&amp;<span class="hl-keyword">mut</span> <span class="hl-keyword">self</span>, m: MarkClosed) <span class="hl-punctuation">-&gt;</span> MarkOpened { <i class="callout" data-value="2"></i></code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">mark</span> = MarkOpened { index: m.index };</code>
<code>    <span class="hl-keyword">self</span>.events.<span class="hl-title function_ invoke__">insert</span>(</code>
<code>      m.index,</code>
<code>      Event::Open { kind: TreeKind::ErrorTree },</code>
<code>    );</code>
<code>    mark</code>
<code>  }</code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<p><span>Here we adjust </span><code>close</code><span> to also return a </span><code>MarkClosed</code><span>, such that we can go back and add a new event before it.</span></p>
</li>
<li>
<p><span>The new API. It is like </span><code>open</code><span>, but also takes a </span><code>MarkClosed</code><span> which carries an index of an </span><code>Open</code><span> event in front of which we are to inject a new </span><code>Open</code><span>.</span>
<span>In the current implementation, for simplicity, we just inject into the middle of the vector, which is an O(N) operation worst-case.</span>
<span>A proper solution here would be to use an index-based linked list.</span>
<span>That is, </span><code>open_before</code><span> can push the new open event to the end of the list, and also mark the old event with a pointer to the freshly inserted one.</span>
<span>To store a pointer, an extra field is needed:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">struct</span> <span class="hl-title class_">Event</span> {</code>
<code>  Open {</code>
<code>    kind: TreeKind,</code>
<code>    <span class="hl-comment">// Points forward into a list at the Open event</span></code>
<code>    <span class="hl-comment">// which logically happens before this one.</span></code>
<code>    open_before: <span class="hl-type">Option</span>&lt;<span class="hl-type">usize</span>&gt;,</code>
<code>  },</code>
<code>}</code></pre>

</figure>
<p><span>The loop in </span><code>build_tree</code><span> needs to follow the </span><code>open_before</code><span> links.</span></p>
</li>
</ol>
<p><span>With this new API, we can parse function calls:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">expr_delimited</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) <span class="hl-punctuation">-&gt;</span> MarkClosed { <i class="callout" data-value="1"></i></code>
<code>  ...</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">expr</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">lhs</span> = <span class="hl-title function_ invoke__">expr_delimited</span>(p); <i class="callout" data-value="1"></i></code>
<code></code>
<code>  <span class="hl-comment">// ExprCall = Expr ArgList</span></code>
<code>  <span class="hl-keyword">while</span> p.<span class="hl-title function_ invoke__">at</span>(LParen) { <i class="callout" data-value="2"></i></code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open_before</span>(lhs);</code>
<code>    <span class="hl-title function_ invoke__">arg_list</span>(p);</code>
<code>    lhs = p.<span class="hl-title function_ invoke__">close</span>(m, ExprCall);</code>
<code>  }</code>
<code>}</code>
<code></code>
<code><span class="hl-comment">// ArgList = &#x27;(&#x27; Arg* &#x27;)&#x27;</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">arg_list</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(LParen));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(LParen);</code>
<code>  <span class="hl-keyword">while</span> !p.<span class="hl-title function_ invoke__">at</span>(RParen) &amp;&amp; !p.<span class="hl-title function_ invoke__">eof</span>() { <i class="callout" data-value="3"></i></code>
<code>    <span class="hl-title function_ invoke__">arg</span>(p);</code>
<code>  }</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(RParen);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, ArgList);</code>
<code>}</code>
<code></code>
<code><span class="hl-comment">// Arg = Expr &#x27;,&#x27;?</span></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">arg</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  <span class="hl-title function_ invoke__">expr</span>(p);</code>
<code>  <span class="hl-keyword">if</span> !p.<span class="hl-title function_ invoke__">at</span>(RParen) { <i class="callout" data-value="4"></i></code>
<code>    p.<span class="hl-title function_ invoke__">expect</span>(Comma);</code>
<code>  }</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, Arg);</code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<p><code>expr_delimited</code><span> now returns a </span><code>MarkClosed</code><span> rather than </span><code>()</code><span>.</span>
<span>No code changes are required for this, as </span><code>close</code><span> calls are already in the tail position.</span></p>
</li>
<li>
<p><span>To parse function calls, we check whether we are at </span><code>(</code><span> and use </span><code>open_before</code><span> API if that is the case.</span></p>
</li>
<li>
<p><span>Parsing argument list should be routine by now.</span>
<span>Again, as an expression can start with many different tokens, we don</span>&rsquo;<span>t add an </span><code>if p.at</code><span> check to the loop</span>&rsquo;<span>s body, and require </span><code>arg</code><span> to consume at least one token.</span></p>
</li>
<li>
<p><span>Inside </span><code>arg</code><span>, we use an already familiar construct to parse an optionally trailing comma.</span></p>
</li>
</ol>
<p><span>Now only binary expressions are left.</span>
<span>We will use a Pratt parser for those.</span>
<span>This is genuinely tricky code, so I have a dedicated article explaining how it all works:</span></p>
<p><span class="display"><a href="https://matklad.github.io/2020/04/13/simple-but-powerful-pratt-parsing.html"><em><span>Simple but Powerful Pratt Parsing</span></em></a><span> .</span></span></p>
<p><span>Here, I</span>&rsquo;<span>ll just dump a pageful of code without much explanation:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">expr</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-title function_ invoke__">expr_rec</span>(p, Eof); <i class="callout" data-value="2"></i></code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">expr_rec</span>(p: &amp;<span class="hl-keyword">mut</span> Parser, left: TokenKind) { <i class="callout" data-value="1"></i></code>
<code>  <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">lhs</span> = <span class="hl-title function_ invoke__">expr_delimited</span>(p);</code>
<code></code>
<code>  <span class="hl-keyword">while</span> p.<span class="hl-title function_ invoke__">at</span>(LParen) {</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open_before</span>(lhs);</code>
<code>    <span class="hl-title function_ invoke__">arg_list</span>(p);</code>
<code>    lhs = p.<span class="hl-title function_ invoke__">close</span>(m, ExprCall);</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">loop</span> {</code>
<code>    <span class="hl-keyword">let</span> <span class="hl-variable">right</span> = p.<span class="hl-title function_ invoke__">nth</span>(<span class="hl-number">0</span>);</code>
<code>    <span class="hl-keyword">if</span> <span class="hl-title function_ invoke__">right_binds_tighter</span>(left, right) { <i class="callout" data-value="1"></i></code>
<code>      <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open_before</span>(lhs);</code>
<code>      p.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>      <span class="hl-title function_ invoke__">expr_rec</span>(p, right);</code>
<code>      lhs = p.<span class="hl-title function_ invoke__">close</span>(m, ExprBinary);</code>
<code>    } <span class="hl-keyword">else</span> {</code>
<code>      <span class="hl-keyword">break</span>;</code>
<code>    }</code>
<code>  }</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">right_binds_tighter</span>( <i class="callout" data-value="1"></i></code>
<code>  left: TokenKind,</code>
<code>  right: TokenKind,</code>
<code>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">bool</span> {</code>
<code>  <span class="hl-keyword">fn</span> <span class="hl-title function_">tightness</span>(kind: TokenKind) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">Option</span>&lt;<span class="hl-type">usize</span>&gt; {</code>
<code>    [</code>
<code>      <span class="hl-comment">// Precedence table:</span></code>
<code>      [Plus, Minus].<span class="hl-title function_ invoke__">as_slice</span>(),</code>
<code>      &amp;[Star, Slash],</code>
<code>    ]</code>
<code>    .<span class="hl-title function_ invoke__">iter</span>()</code>
<code>    .<span class="hl-title function_ invoke__">position</span>(|level| level.<span class="hl-title function_ invoke__">contains</span>(&amp;kind))</code>
<code>  }</code>
<code></code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">Some</span>(right_tightness) = <span class="hl-title function_ invoke__">tightness</span>(right) <span class="hl-keyword">else</span> { <i class="callout" data-value="3"></i></code>
<code>    <span class="hl-keyword">return</span> <span class="hl-literal">false</span></code>
<code>  };</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">Some</span>(left_tightness) = <span class="hl-title function_ invoke__">tightness</span>(left) <span class="hl-keyword">else</span> {</code>
<code>    <span class="hl-built_in">assert!</span>(left == Eof);</code>
<code>    <span class="hl-keyword">return</span> <span class="hl-literal">true</span>;</code>
<code>  };</code>
<code></code>
<code>  right_tightness &gt; left_tightness</code>
<code>}</code></pre>

</figure>
<ol class="callout">
<li>
<p><span>In this version of pratt, rather than passing numerical precedence, I pass the actual token (learned that from </span><a href="https://www.scattered-thoughts.net/writing/better-operator-precedence/"><span>jamii</span>&rsquo;<span>s post</span></a><span>).</span>
<span>So, to determine whether to break or recur in the Pratt loop, we ask which of the two tokens binds tighter and act accordingly.</span></p>
</li>
<li>
<p><span>When we start parsing an expression, we don</span>&rsquo;<span>t have an operator to the left yet, so I just pass </span><code>Eof</code><span> as a dummy token.</span></p>
</li>
<li>
<p><span>The code naturally handles the case when the next token is not an operator (that is, when expression is complete, or when there</span>&rsquo;<span>s some syntax error).</span></p>
</li>
</ol>
<p><span>And that</span>&rsquo;<span>s it! We have parsed the entirety of L!</span></p>
</section>
<section id="Basic-Resilience">

    <h2>
    <a href="#Basic-Resilience"><span>Basic Resilience</span> </a>
    </h2>
<p><span>Let</span>&rsquo;<span>s see how resilient our basic parser is.</span>
<span>Let</span>&rsquo;<span>s check our motivational example:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">fib_rec</span>(f1: <span class="hl-type">u32</span>,</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">fib</span>(n: <span class="hl-type">u32</span>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</code>
<code>  <span class="hl-keyword">return</span> <span class="hl-title function_ invoke__">fib_rec</span>(<span class="hl-number">1</span>, <span class="hl-number">1</span>, n);</code>
<code>}</code></pre>

</figure>
<p><span>Here, the syntax tree our parser produces is surprisingly exactly what we want:</span></p>

<figure class="code-block">


<pre><code>File</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;fib_rec&#x27;</span></code>
<code>    ParamList</code>
<code>      <span class="hl-string">&#x27;(&#x27;</span></code>
<code>      (Param <span class="hl-string">&#x27;f1&#x27;</span> <span class="hl-string">&#x27;:&#x27;</span> (TypeExpr <span class="hl-string">&#x27;u32&#x27;</span>) <span class="hl-string">&#x27;,&#x27;</span>)</code>
<code>    error: expected RParen</code>
<code></code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;fib&#x27;</span></code>
<code>    ...</code></pre>

</figure>
<p><span>For the first incomplete function, we get </span><code>Fn</code><span>, </span><code>Param</code><span> and </span><code>ParamList</code><span>, as we should.</span>
<span>The second function is parsed without any errors.</span></p>
<p><span>Curiously, we get this great result without much explicit effort to make parsing resilient, it</span>&rsquo;<span>s a natural outcome of just not failing in the presence of errors.</span>
<span>The following ingredients help us:</span></p>
<ul>
<li>
<span>homogeneous syntax tree supports arbitrary malformed code,</span>
</li>
<li>
<span>any syntactic construct is parsed left-to-right, and valid prefixes are always recognized,</span>
</li>
<li>
<span>our top-level loop in </span><code>file</code><span> is greedy: it either parses a function, or skips a single token and tries to parse a function again.</span>
<span>That way, if there</span>&rsquo;<span>s a valid function somewhere, it will be recognized.</span>
</li>
</ul>
<p><span>Thinking about the last case both reveals the limitations of our current code, and shows avenues for improvement.</span>
<span>In general, parsing works as a series of nested loops:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">loop</span> { <span class="hl-comment">// parse a list of functions</span></code>
<code></code>
<code>  <span class="hl-keyword">loop</span> { <span class="hl-comment">// parse a list of statements inside a function</span></code>
<code></code>
<code>    <span class="hl-keyword">loop</span> { <span class="hl-comment">// parse a list of expressions</span></code>
<code></code>
<code>    }</code>
<code>  }</code>
<code>}</code></pre>

</figure>
<p><span>If something goes wrong inside a loop, our choices are:</span></p>
<ul>
<li>
<span>skip a token, and continue with the next iteration of the current loop,</span>
</li>
<li>
<span>break out of the inner loop, and let the outer loop handle recovery.</span>
</li>
</ul>
<p><span>The top-most loop must use the </span>&ldquo;<span>skip a token</span>&rdquo;<span> solution, because it needs to consume all of the input tokens.</span></p>
</section>
<section id="Improving-Resilience">

    <h2>
    <a href="#Improving-Resilience"><span>Improving Resilience</span> </a>
    </h2>
<p><span>Right now, each loop either always skips, or always breaks.</span>
<span>This is not optimal.</span>
<span>Consider this example:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">f1</span>(x: <span class="hl-type">i32</span>,</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">f2</span>(x: <span class="hl-type">i32</span>,, z: <span class="hl-type">i32</span>) {}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">f3</span>() {}</code></pre>

</figure>
<p><span>Here, for </span><code>f1</code><span> we want to break out of </span><code>param_list</code><span> loop, and our code does just that.</span>
<span>For </span><code>f2</code><span> though, the error is a duplicated comma (the user will add a new parameter between </span><code>x</code><span> and </span><code>z</code><span> shortly), so we want to skip here.</span>
<span>We don</span>&rsquo;<span>t, and, as a result, the syntax tree for </span><code>f2</code><span> is a train wreck:</span></p>

<figure class="code-block">


<pre><code>Fn</code>
<code>  <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>  <span class="hl-string">&#x27;f2&#x27;</span></code>
<code>  ParamList</code>
<code>    <span class="hl-string">&#x27;(&#x27;</span></code>
<code>    (Param <span class="hl-string">&#x27;x&#x27;</span> <span class="hl-string">&#x27;:&#x27;</span> (TypeExpr <span class="hl-string">&#x27;i32&#x27;</span>) <span class="hl-string">&#x27;,&#x27;</span>)</code>
<code>(ErrorTree <span class="hl-string">&#x27;,&#x27;</span>)</code>
<code>(ErrorTree <span class="hl-string">&#x27;z&#x27;</span>)</code>
<code>(ErrorTree <span class="hl-string">&#x27;:&#x27;</span>)</code>
<code>(ErrorTree <span class="hl-string">&#x27;i32&#x27;</span>)</code>
<code>(ErrorTree <span class="hl-string">&#x27;)&#x27;</span>)</code>
<code>(ErrorTree <span class="hl-string">&#x27;{&#x27;</span>)</code>
<code>(ErrorTree <span class="hl-string">&#x27;}&#x27;</span>)</code></pre>

</figure>
<p><span>For parameters, it is reasonable to skip tokens until we see something which implies the end of the parameter list.</span>
<span>For example, if we are parsing a list of parameters and see an </span><code>fn</code><span> token, then we</span>&rsquo;<span>d better stop.</span>
<span>If we see some less salient token, it</span>&rsquo;<span>s better to gobble it up.</span>
<span>Let</span>&rsquo;<span>s implement the idea:</span></p>

<figure class="code-block">


<pre><code class="hl-line"><span class="hl-keyword">const</span> PARAM_LIST_RECOVERY: &amp;[TokenKind] = &amp;[Arrow, LCurly, FnKeyword];</code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">param_list</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(LParen));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(LParen);</code>
<code>  <span class="hl-keyword">while</span> !p.<span class="hl-title function_ invoke__">at</span>(RParen) &amp;&amp; !p.<span class="hl-title function_ invoke__">eof</span>() {</code>
<code>    <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at</span>(Name) {</code>
<code>      <span class="hl-title function_ invoke__">param</span>(p);</code>
<code>    } <span class="hl-keyword">else</span> {</code>
<code class="hl-line">      <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at_any</span>(PARAM_LIST_RECOVERY) {</code>
<code class="hl-line">        <span class="hl-keyword">break</span>;</code>
<code class="hl-line">      }</code>
<code class="hl-line">      p.<span class="hl-title function_ invoke__">advance_with_error</span>(<span class="hl-string">&quot;expected parameter&quot;</span>);</code>
<code>    }</code>
<code>  }</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(RParen);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, ParamList);</code>
<code>}</code></pre>

</figure>
<p><span>Here, we use </span><code>at_any</code><span> helper function, which is like </span><code>at</code><span>, but takes a list of tokens.</span>
<span>The real implementation would use bitsets for this purpose.</span></p>
<p><span>The example now parses correctly:</span></p>

<figure class="code-block">


<pre><code>File</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;f1&#x27;</span></code>
<code>    ParamList</code>
<code>      <span class="hl-string">&#x27;(&#x27;</span></code>
<code>      (Param <span class="hl-string">&#x27;x&#x27;</span> <span class="hl-string">&#x27;:&#x27;</span> (TypeExpr <span class="hl-string">&#x27;i32&#x27;</span>) <span class="hl-string">&#x27;,&#x27;</span>)</code>
<code>      error: expected RParen</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;f2&#x27;</span></code>
<code>    ParamList</code>
<code>      <span class="hl-string">&#x27;(&#x27;</span></code>
<code>      (Param <span class="hl-string">&#x27;x&#x27;</span> <span class="hl-string">&#x27;:&#x27;</span> (TypeExpr <span class="hl-string">&#x27;i32&#x27;</span>) <span class="hl-string">&#x27;,&#x27;</span>)</code>
<code>      ErrorTree</code>
<code>        error: expected parameter</code>
<code>        <span class="hl-string">&#x27;,&#x27;</span></code>
<code>      (Param <span class="hl-string">&#x27;z&#x27;</span> <span class="hl-string">&#x27;:&#x27;</span> (TypeExpr <span class="hl-string">&#x27;i32&#x27;</span>))</code>
<code>      <span class="hl-string">&#x27;)&#x27;</span></code>
<code>    (Block <span class="hl-string">&#x27;{&#x27;</span> <span class="hl-string">&#x27;}&#x27;</span>)</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;f3&#x27;</span></code>
<code>    (ParamList <span class="hl-string">&#x27;(&#x27;</span> <span class="hl-string">&#x27;)&#x27;</span>)</code>
<code>    (Block <span class="hl-string">&#x27;{&#x27;</span> <span class="hl-string">&#x27;}&#x27;</span>)</code></pre>

</figure>
<p><span>What is a reasonable </span><code>RECOVERY</code><span> set in a general case?</span>
<span>I don</span>&rsquo;<span>t know the answer to this question, but </span><dfn>follow</dfn><span> sets from formal grammar theory give a good intuition.</span>
<span>We don</span>&rsquo;<span>t want </span><em><span>exactly</span></em><span> the </span><dfn>follow</dfn><span> set: for </span><code>ParamList</code><span>, </span><code>{</code><span> is in </span><dfn>follow</dfn><span>, and we do want it to be a part of the recovery set, but </span><code>fn</code><span> is </span><em><span>not</span></em><span> in </span><dfn>follow</dfn><span>, and yet it is important to recover on it.</span>
<code>fn</code><span> is included because it</span>&rsquo;<span>s in the </span><dfn>follow</dfn><span> for </span><code>Fn</code><span>, and </span><code>ParamList</code><span> is a child of </span><code>Fn</code><span>: we also want to recursively include ancestor </span><dfn>follow</dfn><span> sets into the recovery set.</span></p>
<p><span>For expressions and statements, we have the opposite problem </span>&mdash;<span> </span><code>block</code><span> and </span><code>arg_list</code><span> loops eagerly consume erroneous tokens, but sometimes it would be wise to break out of the loop instead.</span></p>
<p><span>Consider this example:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">f</span>() {</code>
<code>  <span class="hl-title function_ invoke__">g</span>(<span class="hl-number">1</span>,</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">x</span> =</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">g</span>() {}</code></pre>

</figure>
<p><span>It gives another train wreck syntax tree, where the </span><code>g</code><span> function is completely missed:</span></p>

<figure class="code-block">


<pre><code>File</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;f&#x27;</span></code>
<code>    (ParamList <span class="hl-string">&#x27;(&#x27;</span> <span class="hl-string">&#x27;)&#x27;</span>)</code>
<code>    Block</code>
<code>      <span class="hl-string">&#x27;{&#x27;</span></code>
<code>      StmtExpr</code>
<code>        ExprCall</code>
<code>          (ExprName <span class="hl-string">&#x27;g&#x27;</span>)</code>
<code>          ArgList</code>
<code>            <span class="hl-string">&#x27;(&#x27;</span></code>
<code>            (Arg (ExprLiteral <span class="hl-string">&#x27;1&#x27;</span>) <span class="hl-string">&#x27;,&#x27;</span>)</code>
<code>            (Arg (ErrorTree <span class="hl-string">&#x27;let&#x27;</span>))</code>
<code>            (Arg (ExprName <span class="hl-string">&#x27;x&#x27;</span>))</code>
<code>            (Arg (ErrorTree <span class="hl-string">&#x27;=&#x27;</span>))</code>
<code>            (Arg (ErrorTree <span class="hl-string">&#x27;}&#x27;</span>))</code>
<code>            (Arg (ErrorTree <span class="hl-string">&#x27;fn&#x27;</span>))</code>
<code>            Arg</code>
<code>              ExprCall</code>
<code>                (ExprName <span class="hl-string">&#x27;g&#x27;</span>)</code>
<code>                (ArgList <span class="hl-string">&#x27;(&#x27;</span> <span class="hl-string">&#x27;)&#x27;</span>)</code>
<code>            (Arg (ErrorTree <span class="hl-string">&#x27;{&#x27;</span>))</code>
<code>            (Arg (ErrorTree <span class="hl-string">&#x27;}&#x27;</span>))</code></pre>

</figure>
<p><span>Recall that the root cause here is that we require </span><code>expr</code><span> to consume at least one token, because it</span>&rsquo;<span>s not immediately obvious which tokens can start an expression.</span>
<span>It</span>&rsquo;<span>s not immediately obvious, but easy to compute </span>&mdash;<span> that</span>&rsquo;<span>s exactly </span><dfn>first</dfn><span> set from formal grammars.</span></p>
<p><span>Using it, we get:</span></p>

<figure class="code-block">


<pre><code class="hl-line"><span class="hl-keyword">const</span> STMT_RECOVERY: &amp;[TokenKind] = &amp;[FnKeyword];</code>
<code class="hl-line"><span class="hl-keyword">const</span> EXPR_FIRST: &amp;[TokenKind] =</code>
<code class="hl-line">  &amp;[Int, TrueKeyword, FalseKeyword, Name, LParen];</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">block</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(LCurly));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(LCurly);</code>
<code>  <span class="hl-keyword">while</span> !p.<span class="hl-title function_ invoke__">at</span>(RCurly) &amp;&amp; !p.<span class="hl-title function_ invoke__">eof</span>() {</code>
<code>    <span class="hl-keyword">match</span> p.<span class="hl-title function_ invoke__">nth</span>(<span class="hl-number">0</span>) {</code>
<code>      LetKeyword =&gt; <span class="hl-title function_ invoke__">stmt_let</span>(p),</code>
<code>      ReturnKeyword =&gt; <span class="hl-title function_ invoke__">stmt_return</span>(p),</code>
<code>      _ =&gt; {</code>
<code class="hl-line">        <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at_any</span>(EXPR_FIRST) {</code>
<code class="hl-line">          <span class="hl-title function_ invoke__">stmt_expr</span>(p)</code>
<code class="hl-line">        } <span class="hl-keyword">else</span> {</code>
<code class="hl-line">          <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at_any</span>(STMT_RECOVERY) {</code>
<code class="hl-line">            <span class="hl-keyword">break</span>;</code>
<code class="hl-line">          }</code>
<code class="hl-line">          p.<span class="hl-title function_ invoke__">advance_with_error</span>(<span class="hl-string">&quot;expected statement&quot;</span>);</code>
<code class="hl-line">        }</code>
<code>      }</code>
<code>    }</code>
<code>  }</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(RCurly);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, Block);</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">arg_list</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) {</code>
<code>  <span class="hl-built_in">assert!</span>(p.<span class="hl-title function_ invoke__">at</span>(LParen));</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(LParen);</code>
<code>  <span class="hl-keyword">while</span> !p.<span class="hl-title function_ invoke__">at</span>(RParen) &amp;&amp; !p.<span class="hl-title function_ invoke__">eof</span>() {</code>
<code class="hl-line">    <span class="hl-keyword">if</span> p.<span class="hl-title function_ invoke__">at_any</span>(EXPR_FIRST) {</code>
<code class="hl-line">      <span class="hl-title function_ invoke__">arg</span>(p);</code>
<code class="hl-line">    } <span class="hl-keyword">else</span> {</code>
<code class="hl-line">        <span class="hl-keyword">break</span>;</code>
<code class="hl-line">    }</code>
<code>  }</code>
<code>  p.<span class="hl-title function_ invoke__">expect</span>(RParen);</code>
<code></code>
<code>  p.<span class="hl-title function_ invoke__">close</span>(m, ArgList);</code>
<code>}</code></pre>

</figure>
<p><span>This fixes the syntax tree:</span></p>

<figure class="code-block">


<pre><code>File</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;f&#x27;</span></code>
<code>    (ParamList <span class="hl-string">&#x27;(&#x27;</span> <span class="hl-string">&#x27;)&#x27;</span>)</code>
<code>    Block</code>
<code>      <span class="hl-string">&#x27;{&#x27;</span></code>
<code>      StmtExpr</code>
<code>        ExprCall</code>
<code>          (ExprName <span class="hl-string">&#x27;g&#x27;</span>)</code>
<code>          ArgList</code>
<code>            <span class="hl-string">&#x27;(&#x27;</span></code>
<code>            (Arg (ExprLiteral <span class="hl-string">&#x27;1&#x27;</span> <span class="hl-string">&#x27;,&#x27;</span>))</code>
<code>      StmtLet</code>
<code>        <span class="hl-string">&#x27;let&#x27;</span></code>
<code>        <span class="hl-string">&#x27;x&#x27;</span></code>
<code>        <span class="hl-string">&#x27;=&#x27;</span></code>
<code>        (ErrorTree <span class="hl-string">&#x27;}&#x27;</span>)</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;g&#x27;</span></code>
<code>    (ParamList <span class="hl-string">&#x27;(&#x27;</span> <span class="hl-string">&#x27;)&#x27;</span>)</code>
<code>    (Block <span class="hl-string">&#x27;{&#x27;</span> <span class="hl-string">&#x27;}&#x27;</span>)</code></pre>

</figure>
<p><span>There</span>&rsquo;<span>s only one issue left.</span>
<span>Our </span><code>expr</code><span> parsing is still greedy, so, in a case like this</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">f</span>() {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">x</span> = <span class="hl-number">1</span> +</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">y</span> = <span class="hl-number">2</span></code>
<code>}</code></pre>

</figure>
<p><span>the </span><code>let</code><span> will be consumed as a right-hand-side operand of </span><code>+</code><span>.</span>
<span>Now that the callers of </span><code>expr</code><span> contain a check for </span><code>EXPR_FIRST</code><span>, we no longer need this greediness and can return </span><code>None</code><span> if no expression can be parsed:</span></p>

<figure class="code-block">


<pre><code class="hl-line"><span class="hl-keyword">fn</span> <span class="hl-title function_">expr_delimited</span>(p: &amp;<span class="hl-keyword">mut</span> Parser) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">Option</span>&lt;MarkClosed&gt; {</code>
<code>  <span class="hl-keyword">let</span> <span class="hl-variable">result</span> = <span class="hl-keyword">match</span> p.<span class="hl-title function_ invoke__">nth</span>(<span class="hl-number">0</span>) {</code>
<code>    <span class="hl-comment">// ExprLiteral = &#x27;int&#x27; | &#x27;true&#x27; | &#x27;false&#x27;</span></code>
<code>    Int | TrueKeyword | FalseKeyword =&gt; {</code>
<code>      <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code>      p.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>      p.<span class="hl-title function_ invoke__">close</span>(m, ExprLiteral)</code>
<code>    }</code>
<code></code>
<code>    <span class="hl-comment">// ExprName = &#x27;name&#x27;</span></code>
<code>    Name =&gt; {</code>
<code>      <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code>      p.<span class="hl-title function_ invoke__">advance</span>();</code>
<code>      p.<span class="hl-title function_ invoke__">close</span>(m, ExprName)</code>
<code>    }</code>
<code></code>
<code>    <span class="hl-comment">// ExprParen   = &#x27;(&#x27; Expr &#x27;)&#x27;</span></code>
<code>    LParen =&gt; {</code>
<code>      <span class="hl-keyword">let</span> <span class="hl-variable">m</span> = p.<span class="hl-title function_ invoke__">open</span>();</code>
<code>      p.<span class="hl-title function_ invoke__">expect</span>(LParen);</code>
<code>      <span class="hl-title function_ invoke__">expr</span>(p);</code>
<code>      p.<span class="hl-title function_ invoke__">expect</span>(RParen);</code>
<code>      p.<span class="hl-title function_ invoke__">close</span>(m, ExprParen)</code>
<code>    }</code>
<code></code>
<code>    _ =&gt; {</code>
<code class="hl-line">      <span class="hl-built_in">assert!</span>(!p.<span class="hl-title function_ invoke__">at_any</span>(EXPR_FIRST));</code>
<code class="hl-line">      <span class="hl-keyword">return</span> <span class="hl-literal">None</span>;</code>
<code>    }</code>
<code>  };</code>
<code>  <span class="hl-title function_ invoke__">Some</span>(result)</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span> <span class="hl-title function_">expr_rec</span>(p: &amp;<span class="hl-keyword">mut</span> Parser, left: TokenKind) {</code>
<code class="hl-line">  <span class="hl-keyword">let</span> <span class="hl-variable">Some</span>(<span class="hl-keyword">mut</span> lhs) = <span class="hl-title function_ invoke__">expr_delimited</span>(p) <span class="hl-keyword">else</span> {</code>
<code class="hl-line">    <span class="hl-keyword">return</span>;</code>
<code class="hl-line">  };</code>
<code>  ...</code>
<code>}</code></pre>

</figure>
<p><span>This gives the following syntax tree:</span></p>

<figure class="code-block">


<pre><code>File</code>
<code>  Fn</code>
<code>    <span class="hl-string">&#x27;fn&#x27;</span></code>
<code>    <span class="hl-string">&#x27;f&#x27;</span></code>
<code>    (ParamList <span class="hl-string">&#x27;(&#x27;</span> <span class="hl-string">&#x27;)&#x27;</span>)</code>
<code>    Block</code>
<code>      <span class="hl-string">&#x27;{&#x27;</span></code>
<code>      StmtLet</code>
<code>        <span class="hl-string">&#x27;let&#x27;</span></code>
<code>        <span class="hl-string">&#x27;x&#x27;</span></code>
<code>        <span class="hl-string">&#x27;=&#x27;</span></code>
<code>        (ExprBinary (ExprLiteral <span class="hl-string">&#x27;1&#x27;</span>) <span class="hl-string">&#x27;+&#x27;</span>)</code>
<code>      StmtLet</code>
<code>        <span class="hl-string">&#x27;let&#x27;</span></code>
<code>        <span class="hl-string">&#x27;y&#x27;</span></code>
<code>        <span class="hl-string">&#x27;=&#x27;</span></code>
<code>        (ExprLiteral <span class="hl-string">&#x27;2&#x27;</span>)</code>
<code>      <span class="hl-string">&#x27;}&#x27;</span></code></pre>

</figure>
<p><span>And this concludes the tutorial!</span>
<span>You are now capable of implementing an IDE-grade parser for a real programming language from scratch.</span></p>
<p><span>Summarizing:</span></p>
<ul>
<li>
<p><span>Resilient parsing means recovering as much syntactic structure from erroneous code as possible.</span></p>
</li>
<li>
<p><span>Resilient parsing is important for IDEs and language servers, who</span>&rsquo;<span>s job mostly ends when the code does not have errors any more.</span></p>
</li>
<li>
<p><span>Resilient parsing is related, but distinct from error recovery and repair.</span>
<span>Rather than guessing what the user meant to write, the parser tries to make sense of what is actually written.</span></p>
</li>
<li>
<p><span>Academic literature tends to focus on error repair, and mostly ignores pure resilience.</span></p>
</li>
<li>
<p><span>The biggest challenge of resilient parsing is the design of a syntax tree data structure.</span>
<span>It should provide convenient and type-safe access to well-formed syntax trees, while allowing arbitrary malformed trees.</span></p>
</li>
<li>
<p><span>One possible design here is to make the underlying tree a dynamically-typed data structure (like JSON), and layer typed accessors on top (not covered in this article).</span></p>
</li>
<li>
<p><span>LL style parsers are a good fit for resilient parsing.</span>
<span>Because code is written left-to-right, it</span>&rsquo;<span>s important that the parser recognizes well-formed prefixes of incomplete syntactic constructs, and LL does just that.</span></p>
</li>
<li>
<p><span>Ultimately, parsing works as a stack of nested </span><code>for</code><span> loops.</span>
<span>Inside a single </span><code>for</code><span> loop, on each iteration, we need to decide between:</span></p>
<ul>
<li>
<span>trying to parse a sequence element,</span>
</li>
<li>
<span>skipping over an unexpected token,</span>
</li>
<li>
<span>breaking out of the nested loop and delegating recovery to the parent loop.</span>
</li>
</ul>
</li>
<li>
<p><dfn>first</dfn><span>, </span><dfn>follow</dfn><span> and recovery sets help making a specific decision.</span></p>
</li>
<li>
<p><span>In any case, if a loop tries to parse an item, item parsing </span><em><span>must</span></em><span> consume at least one token (if only to report an error).</span></p>
</li>
</ul>
<script type="module" src="/assets/resilient-parsing/main.js"></script>
<p><span>Source code for the article is here: </span><span class="display"><a href="https://github.com/matklad/resilient-ll-parsing/blob/master/src/lib.rs#L44" class="url">https://github.com/matklad/resilient-ll-parsing/blob/master/src/lib.rs#L44</a><span> .</span></span></p>
</section>
]]></content>
</entry>

<entry>
<title type="text">Zig Language Server And Cancellation</title>
<link href="https://matklad.github.io/2023/05/06/zig-language-server-and-cancellation.html" rel="alternate" type="text/html" title="Zig Language Server And Cancellation" />
<published>2023-05-06T00:00:00+00:00</published>
<updated>2023-05-06T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/05/06/zig-language-server-and-cancellation</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[I already have a dedicated post about a hypothetical Zig language server.
But perhaps the most important thing I've written so far on the topic is the short note at the end of Zig and Rust.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/05/06/zig-language-server-and-cancellation.html"><![CDATA[
    <h1>
    <a href="#Zig-Language-Server-And-Cancellation"><span>Zig Language Server And Cancellation</span> <time datetime="2023-05-06">May 6, 2023</time></a>
    </h1>
<p><span>I already have a dedicated post about a hypothetical </span><a href="https://matklad.github.io/2023/02/10/how-a-zig-ide-could-work.html"><span>Zig language server</span></a><span>.</span>
<span>But perhaps the most important thing I</span>&rsquo;<span>ve written so far on the topic is the short note at the end of </span><a href="https://matklad.github.io/2023/03/26/zig-and-rust.html#ide"><em><span>Zig and Rust</span></em></a><span>.</span></p>
<p><span>If you want to implement an LSP for a language, you need to start with a data model.</span>
<span>If you correctly implement a store of source code which evolves over time and allows computing (initially trivial) derived data, then filling in the data until it covers the whole language is a question of incremental improvement.</span>
<span>If, however, you don</span>&rsquo;<span>t start with a rock-solid data model, and rush to implement language features, you might find yourself needing to make a sharp U-turn several years down the road.</span></p>
<p><span>I find this pretty insightful!</span>
<span>At least, this evening I</span>&rsquo;<span>ve been pondering a  particular aspect of the data model, and I think I realized something new about the problem space!</span>
<span>The aspect is cancellation.</span></p>
<section id="Cancellation">

    <h2>
    <a href="#Cancellation"><span>Cancellation</span> </a>
    </h2>
<p><span>Consider this.</span>
<span>Your language server is happily doing something very useful and computationally-intensive </span>&mdash;
<span>typechecking a </span><a href="https://github.com/microsoft/TypeScript/blob/04d4580f4eedc036b014ef4329cffe9979da3af9/src/compiler/checker.ts"><span>giant typechecker</span></a><span>,</span>
<span>computing comptime </span><a href="https://en.wikipedia.org/wiki/Ackermann_function"><span>Ackermann function</span></a><span>,</span>
<span>or </span><a href="https://github.com/launchbadge/sqlx#sqlx-is-not-an-orm"><span>talking to Postgres</span></a><span>.</span>
<span>Now, the user comes in and starts typing in the very file the server is currently processing.</span>
<span>What is the desired behavior, and how could it be achieved?</span></p>
<p><span>One useful model here is strong consistency.</span>
<span>If the language server acknowledged a source code edit, all future semantic requests (like </span>&ldquo;<span>go to definition</span>&rdquo;<span> or </span>&ldquo;<span>code completion</span>&rdquo;<span>) reflect this change.</span>
<span>The behavior is </span><em><span>as if</span></em><span> all changes and requests are sequentially ordered, and the server fully processes all preceding edits before responding to a request.</span>
<span>There are two great benefits to this model.</span>
<span>First, for the implementor it</span>&rsquo;<span>s an easy model to reason about. It</span>&rsquo;<span>s always clear what the answer to a particular request should be, the model is fully deterministic.</span>
<span>Second, the model gives maximally useful guarantees to the user, strict serializability.</span></p>
<p><span>So consider this sequence of events:</span></p>
<ol>
<li>
<span>User types </span><code>fo</code><span>.</span>
</li>
<li>
<span>The editor sends the edit to the language server.</span>
</li>
<li>
<span>The editor requests completions for </span><code>fo</code><span>.</span>
</li>
<li>
<span>The server starts furiously typechecking modified file to compute the result.</span>
</li>
<li>
<span>User types </span><code>o</code><span>.</span>
</li>
<li>
<span>The editor sends the </span><code>o</code><span>.</span>
</li>
<li>
<span>The editor re-requests completions, now for </span><code>foo</code><span>.</span>
</li>
</ol>
<p><span>How does the server deal with this?</span></p>
<p><span>The trivial solution is to run everything sequentially to completion.</span>
<span>So, on the step </span><code>6</code><span>, the server doesn</span>&rsquo;<span>t immediately acknowledge the edit, but rather blocks until it fully completes </span><code>4</code><span>.</span>
<span>This is a suboptimal behavior, because reads (computing completion) block writes (updating source code).</span>
<span>As a rule of thumb, writes should be prioritized over reads, because they reflect more up-to-date and more useful data.</span></p>
<p><span>A more optimal solution is to make the whole data model of the server immutable, such that edits do not modify data inplace, but rather create a separate, new state.</span>
<span>In this model, computing results for </span><code>3</code><span> and </span><code>7</code><span> proceeds in parallel, and, crucially, the edit </span><code>6</code><span> is accepted immediately.</span>
<span>The cost of this model is the requirement that all data structures are immutable.</span>
<span>It also is a bit wasteful </span>&mdash;<span> burning CPU to compute code completion for an already old file is useless, better dedicate all cores to the latest version.</span></p>
<p><span>A third approach is cancellation.</span>
<span>On step </span><code>6</code><span>, when the server becomes aware about the pending edit, it actively cancels all in-flight work pertaining to the old state and then applies modification in-place.</span>
<span>That way we don</span>&rsquo;<span>t need to defensively copy the data, and also avoid useless CPU work.</span>
<span>This is the strategy employed by rust-analyzer.</span></p>
<p><span>It</span>&rsquo;<span>s useful to think about why the server can</span>&rsquo;<span>t just, like, apply the edit in place completely ignoring any possible background work.</span>
<span>The edit ultimately changes some memory somewhere, which might be concurrently read by the code completion thread, yielding a data race and full-on UB.</span>
<span>It is possible to work-around this by applying </span><a href="https://dl.acm.org/doi/10.1145/2723372.2737784"><span>feral concurrency control</span></a><span> and just wrapping each individual bit of data in a mutex.</span>
<span>This removes the data race, but leads to excessive synchronization, sprawling complexity and broken logical invariants (function body might change in the middle of typechecking).</span></p>
<p><span>Finally, there</span>&rsquo;<span>s this final solution, or rather, idea for a solution.</span>
<span>One interesting approach for dealing with memory which is needed now, but not in the future, is semi-space garbage collection.</span>
<span>We divide the available memory in two equal parts, use one half as a working copy which accumulates useful objects and garbage, and then at some point switch the halves, copying the live objects (but not the garbage) over.</span>
<span>Another place where this idea comes up is Carmack</span>&rsquo;<span>s architecture for functional games.</span>
<span>On every frame, a game copies over the game state applying frame update function.</span>
<span>Because frames happen sequentially, you only need two copies of game state for this.</span>
<span>We can think about applying something like that for cancellation </span>&mdash;<span> without going for full immutability, we can let cancelled analysis to work with the old half-state, while we switch to the new one.</span></p>
<p><span>This </span>&hellip;<span> is not particularly actionable, but a good set of ideas to start thinking about evolution of a state in a language server.</span>
<span>And now for something completely different!</span></p>
</section>
<section id="Relaxed-Consistency">

    <h2>
    <a href="#Relaxed-Consistency"><span>Relaxed Consistency</span> </a>
    </h2>
<p><span>The strict consistency is a good default, and works especially well for languages with good support for separate compilation, as the amount of work a language server needs to do after an update is proportional to the size of the update, and to the amount of code on the screen, both of which are typically O(1).</span>
<span>For Zig, whose compilation model is </span>&ldquo;<span>start from the entry point and lazily compile everything that</span>&rsquo;<span>s actually used</span>&rdquo;<span>, this might be difficult to pull off.</span>
<span>It seems that Zig naturally gravitates to a smalltalk-like image-based programming model, where the server stores fully resolved code all the time, and, if some edit triggers re-analysis of a huge chunk of code, the user just has to wait until the server catches up.</span></p>
<p><span>But what if we don</span>&rsquo;<span>t do strong consistency?</span>
<span>What if we allow IDE to temporarily return non-deterministic and wrong results?</span>
<span>I think we can get some nice properties in exchange, if we use that semi-space idea.</span></p>
<p><span>The state of our language server would be comprised of three separate pieces of data:</span></p>
<ul>
<li>
<span>A fully analyzed snapshot of the world, </span><strong><code>ready</code></strong><span>.</span>
<span>This is a bunch of source file, plus their ASTs, ZIRs and AIRs.</span>
<span>This also probably contains an index of cross-references, so that finding all usages of an identifier requires just listing already precomputed results.</span>
</li>
<li>
<span>The next snapshot, which is being analyzed, </span><strong><code>working</code></strong><span>.</span>
<span>This is essentially the same data, but the AIR is being constructed.</span>
<span>We need </span><em><span>two</span></em><span> snapshots because we want to be able to query one of them while the second one is being updated.</span>
</li>
<li>
<span>Finally, we also hold ASTs for the files which are currently being modified, </span><strong><code>pending</code></strong><span>.</span>
</li>
</ul>
<p><span>The overall evolution of data is as follows.</span></p>
<p><span>All edits synchronously go to the </span><code>pending</code><span> state.</span>
<code>pending</code><span> is organized strictly on a per-file basis, so updating it can be done quickly on the main thread (maaaybe we want to move the parsing off the main thread, but my gut feeling is that we don</span>&rsquo;<span>t need to).</span>
<code>pending</code><span> always reflects the latest state of the world, it </span><em><span>is</span></em><span> the latest state of the world.</span></p>
<p><span>Periodically, we collect a batch of changes from </span><code>pending</code><span>, create a new </span><code>working</code><span> and kick off a full analysis in background.</span>
<span>A good point to do that would be when there</span>&rsquo;<span>s no syntax errors, or when the user saves a file.</span>
<span>There</span>&rsquo;<span>s at most one analysis in progress, so we accumulate changes in </span><code>pending</code><span> until the previous analysis finishes.</span></p>
<p><span>When </span><code>working</code><span> is fully processed, we atomically update the </span><code>ready</code><span>.</span>
<span>As </span><code>ready</code><span> is just an inert piece of data, it can be safely accessed from whatever thread.</span></p>
<p><span>When processing requests, we only use </span><code>ready</code><span> and </span><code>pending</code><span>.</span>
<span>Processing requires some heuristics.</span>
<code>ready</code><span> and </span><code>pending</code><span> describe different states of the world.</span>
<code>pending</code><span> guarantees that its state is up-to-date, but it only has AST-level data.</span>
<code>ready</code><span> is outdated, </span><em><span>but</span></em><span> it has every bit of semantic information pre-computed.</span>
<span>In particular, it includes cross-reference data.</span></p>
<p><span>So, our choices for computing results are:</span></p>
<ul>
<li>
<p><span>Use the </span><code>pending</code><span> AST.</span>
<span>Features like displaying the outline of the current file or globally fuzzy-searching function by name can be implemented like this.</span>
<span>These features always give correct results.</span></p>
</li>
<li>
<p><span>Find the match between the </span><code>pending</code><span> AST and the </span><code>ready</code><span> semantics.</span>
<span>This works perfectly for non-local </span>&ldquo;<span>goto definition</span>&rdquo;<span>.</span>
<span>Here, we can temporarily get </span>&ldquo;<span>wrong</span>&rdquo;<span> results, or no result at all.</span>
<span>However, the results we get are always instant.</span></p>
</li>
<li>
<p><span>Re-analyze </span><code>pending</code><span> AST using results from </span><code>ready</code><span> for the analysis of the context.</span>
<span>This is what we</span>&rsquo;<span>ll use for code completion.</span>
<span>For code completion, </span><code>pending</code><span> will be maximally diverging from </span><code>ready</code><span> (especially if we use </span>&ldquo;<span>no syntax errors</span>&rdquo;<span> as a heuristic for promoting </span><code>pending</code><span> to </span><code>working</code><span>),</span>
<span>so we won</span>&rsquo;<span>t be able to complete based purely on </span><code>ready</code><span>.</span>
<span>At the same time, completion is heavily semantics-dependent, so we won</span>&rsquo;<span>t be able to drive it through </span><code>pending</code><span>.</span>
<span>And we also can</span>&rsquo;<span>t launch full semantic analysis on </span><code>pending</code><span> (what we effectively do in </span><code>rust-analyzer</code><span>), due to </span>&ldquo;<span>from root</span>&rdquo;<span> analysis nature.</span></p>
<p><span>But we can merge two analysis techniques.</span>
<span>For example, if we are completing in a function which starts as </span><span class="display"><code>fn f(comptime T: type, param: T)</code><span>,</span></span>
<span>we can use </span><code>ready</code><span> to get a set of values of </span><code>T</code><span> the function is actually called with, to complete </span><code>param.</code><span> in a useful way.</span>
<span>Dually, if inside </span><code>f</code><span> we have something like </span><span class="display"><code>const list = std.ArrayList(u32){}</code><span>,</span></span><span> we don</span>&rsquo;<span>t have to </span><code>comptime</code><span> evaluate the </span><code>ArrayList</code><span> function, we can fetch the result from </span><code>ready</code><span>.</span></p>
<p><span>Of course, we must also handle the case where there</span>&rsquo;<span>s no </span><code>ready</code><span> yet (it</span>&rsquo;<span>s a first compilation, or we switched branches), so completion would be somewhat non-deterministic.</span></p>
</li>
</ul>
<p><span>One important flow where non-determinism would get in a way is refactoring.</span>
<span>When you rename something, you should be 100% sure that you</span>&rsquo;<span>ve found all usages.</span>
<span>So, any refactor would have to be a blocking operation where we first wait for the current </span><code>working</code><span> to complete, then update </span><code>working</code><span> with the </span><code>pending</code><span> accumulated so far, and wait for </span><em><span>that</span></em><span> to complete, to, finally, apply the refactor using only up-to-date </span><code>ready</code><span>.</span>
<span>Luckily, refactoring is almost always a two-phase flow, reminiscent of a GET/POST flow for HTTP form (</span><a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html"><span>more about that</span></a><span>).</span>
<span>Any refactor starts with read-only analysis to inform the user about available options and to gather input.</span>
<span>For </span>&ldquo;<span>rename</span>&rdquo;<span>, you wait for the user to type the new name, for </span>&ldquo;<span>change signature</span>&rdquo;<span> the user needs to rearrange params.</span>
<span>This brief interactive window should give enough headroom to flush all </span><code>pending</code><span> changes, masking the latency.</span></p>
<p><span>I am pretty excited about this setup.</span>
<span>I think that</span>&rsquo;<span>s the way to go for Zig.</span></p>
<ul>
<li>
<span>The approach meshes extremely well with the ambition of doing incremental binary patching, both because it leans on complete global analysis, and because it contains an explicit notion of switching from one snapshot to the next one</span>
<span>(in contrast, rust-analyzer never really thinks about </span>&ldquo;<span>previous</span>&rdquo;<span> state of the code. There</span>&rsquo;<span>s always only the </span>&ldquo;<span>current</span>&rdquo;<span> state, with lazy, partially complete analysis).</span>
</li>
<li>
<span>Zig lacks declared interfaces, so a quick </span>&ldquo;<span>find all calls to this function</span>&rdquo;<span> operation is required for useful completion.</span>
<span>Fully resolved historical snapshot gives us just that.</span>
</li>
<li>
<span>Zig is carefully designed to make a lot of semantic information obvious just from the syntax.</span>
<span>Unlike Rust, Zig lacks syntactic macros or glob imports.</span>
<span>This makes is possible to do a lot of analysis correctly using only </span><code>pending</code><span> ASTs.</span>
</li>
<li>
<span>This approach nicely dodges the cancellation problem I</span>&rsquo;<span>ve spend half of the blog post explaining, and has a relatively simple threading story, which reduces implementation complexity.</span>
</li>
<li>
<span>Finally, it feels like it should be </span><em><span>super</span></em><span> fast (if not the most CPU efficient).</span>
</li>
</ul>

<figure>

<img alt="" src="/assets/zig-lsp.jpg">
</figure>
<p><span>Discussion on </span><a href="https://old.reddit.com/r/Zig/comments/13a8d9l/blog_post_zig_language_server_and_cancellation/"><span>/r/Zig</span></a><span>.</span></p>
</section>
]]></content>
</entry>

<entry>
<title type="text">Value Oriented Programming Needs Implicits?</title>
<link href="https://matklad.github.io/2023/05/02/implicits-for-mvs.html" rel="alternate" type="text/html" title="Value Oriented Programming Needs Implicits?" />
<published>2023-05-02T00:00:00+00:00</published>
<updated>2023-05-02T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/05/02/implicits-for-mvs</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[An amateur note on language design which explores two important questions:]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/05/02/implicits-for-mvs.html"><![CDATA[
    <h1>
    <a href="#Value-Oriented-Programming-Needs-Implicits"><span>Value Oriented Programming Needs Implicits?</span> <time datetime="2023-05-02">May 2, 2023</time></a>
    </h1>
<p><span>An amateur note on language design which explores two important questions:</span></p>
<ul>
<li>
<span>How to do polymorphism?</span>
</li>
<li>
<span>How to do anything at all?</span>
</li>
</ul>
<p><span>Let</span>&rsquo;<span>s start with the second question.</span>
<span>What is the basic stuff that everything else is made of?</span></p>
<p><span>Not so long ago, the most popular answer to that question was </span>&ldquo;<span>objects</span>&rdquo;<span> </span>&mdash;<span> blobs of mutable state with references to other blobs.</span>
<span>This turned out to be problematic </span>&mdash;<span> local mutation of an object might accidentally cause unwanted changes elsewhere.</span>
<span>Defensive copying of collections at the API boundary was a common pattern.</span></p>
<p><span>Another answer to the question of basic stuff  is </span>&ldquo;<span>immutable values</span>&rdquo;<span>, as exemplified by functional programming.</span>
<span>This fixes the ability to reason about programs locally at the cost of developer ergonomics and expressiveness.</span>
<span>A lot of code is naturally formulated in terms of </span>&ldquo;<span>let</span>&rsquo;<span>s mutate this little thing</span>&rdquo;<span>, and functionally threading the update through all the layers is tiresome.</span></p>
<p><span>The C answer is that everything is made of </span>&ldquo;<span>memory (*)</span>&rdquo;<span>.</span>
<span>It is almost as if memory is an array of bytes.</span>
<span>Almost, but not quite </span>&mdash;<span> to write portable programs amenable to optimization, certain restrictions must be placed on the ways memory is accessed and manipulated, hence (*).</span>
<span>These restrictions not being checked by the compiler (and not even visible in the source code) create a fertile ground for subtle bugs.</span></p>
<p><span>Rust takes this basic C model and:</span></p>
<ul>
<li>
<span>Makes the (*) explicit:</span>
<ul>
<li>
<span>pointers always carry the size of addressed memory, possibly at runtime (slices),</span>
</li>
<li>
<span>pointers carry lifetime, accessing the data past the end of the lifetime is forbidden.</span>
</li>
</ul>
</li>
<li>
<span>Adds aliasing information to the type system, such that it becomes possible to tell if there are </span><em><span>other</span></em><span> pointers pointing at a particular piece of memory.</span>
</li>
</ul>
<p><span>Curiously, this approach allows rust to have an </span>&ldquo;<span>immutable values</span>&rdquo;<span> feel, without requiring the user to thread updates manually,</span>
<a href="http://smallcultfollowing.com/babysteps/blog/2018/02/01/in-rust-ordinary-vectors-are-values/">&ldquo;<span>In Rust, Ordinary Vectors are Values</span>&rdquo;</a><span>.</span>
<span>But the cognitive cost for this approach is pretty high, as the universe of values is now forked by different flavors of owning/referencing.</span></p>
<p><span>Let</span>&rsquo;<span>s go back to the pure FP model.</span>
<span>Can we just locally fix it?</span>
<span>Let</span>&rsquo;<span>s take a look at an example:</span></p>

<figure class="code-block">


<pre><code>let xs1 = get_items() in</code>
<code>let xs2  = modify_items(xs1) in</code>
<code>let xs3 = sort_items(xs2) in</code>
<code>...</code></pre>

</figure>
<p><span>It is pretty clear that we can allow mutation of local variables via a simple rewrite, as that won</span>&rsquo;<span>t compromise local reasoning:</span></p>

<figure class="code-block">


<pre><code>var xs = get_items()</code>
<code>xs = modify_items(xs)</code>
<code>xs = sort_items(xs)</code></pre>

</figure>
<p><span>Similarly, we can introduce a rewrite rule for the ubiquitous </span><code>x = f(x)</code><span> pattern, such that the code looks like this:</span></p>

<figure class="code-block">


<pre><code>var xs = get_items()</code>
<code>modify_items(xs)</code>
<code>sort_items(xs)</code></pre>

</figure>
<p><span>Does this actually work?</span>
<span>Yes, it does, as popularized by Swift and distilled in its pure form by </span><a href="https://www.val-lang.dev"><span>Val</span></a><span>.</span></p>
<p><span>Formalizing the rewriting reasoning, we introduce second-class references, which can </span><em><span>only</span></em><span> appear in function arguments (</span><code>inout</code><span> parameters), but, eg, can</span>&rsquo;<span>t be stored as fields.</span>
<span>With these restrictions, </span>&ldquo;<span>borrow checking</span>&rdquo;<span> becomes fairly simple </span>&mdash;<span> at each function call it suffices to check that no two </span><code>inout</code><span> arguments overlap.</span></p>
<p><span>Now, let</span>&rsquo;<span>s switch gears and explore the second question </span>&mdash;<span> polymorphism.</span></p>
<p><span>Starting again with OOP, you can use subtyping with its familiar </span><span class="display"><code>class Dog extends Triangle</code><span>,</span></span><span> but that is not very flexible.</span>
<span>In particular, expressing something like </span>&ldquo;<span>sorting a list of items</span>&rdquo;<span> with pure subtyping is not too natural.</span>
<span>What works better is parametric polymorphism, where you add type parameters to your data structures:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">sort</span>&lt;T&gt;(items: &amp;<span class="hl-keyword">mut</span> <span class="hl-type">Vec</span>&lt;T&gt;)</code></pre>

</figure>
<p><span>Except that it doesn</span>&rsquo;<span>t quite work as, as we also need to specify how to sort the </span><code>T</code><span>s.</span>
<span>One approach here would be to introduce some sort of type-of-types, to group types with similar traits into a class:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">sort</span>&lt;T: Comparable&gt;(items: &amp;<span class="hl-keyword">mut</span> <span class="hl-type">Vec</span>&lt;T&gt;)</code></pre>

</figure>
<p><span>A somewhat simpler approach is to just explicitly pass in a comparison function:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span> <span class="hl-title function_">sort</span>&lt;T&gt;(</code>
<code>    compare: <span class="hl-title function_ invoke__">fn</span>(T, T) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">bool</span>,</code>
<code>    items: &amp;<span class="hl-keyword">mut</span> <span class="hl-type">Vec</span>&lt;T&gt;,</code>
<code>)</code></pre>

</figure>
<p><span>How does this relate to value oriented programming?</span>
<span>It happens that, when programming with values, a very common pattern is to use indexes to express relationships.</span>
<span>For example, to model parent-child relations (or arbitrary graphs), the following setup works:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">type</span> <span class="hl-title class_">Tree</span> = <span class="hl-type">Vec</span>&lt;Node&gt;;</code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">Node</span> {</code>
<code>    parent: <span class="hl-type">usize</span>,</code>
<code>    children: <span class="hl-type">Vec</span>&lt;<span class="hl-type">usize</span>&gt;,</code>
<code>}</code></pre>

</figure>
<p><span>Using direct references hits language limitations:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">struct</span> <span class="hl-title class_">Node</span> {</code>
<code>    parent: Node, <span class="hl-comment">// Who owns that?</span></code>
<code>    children: <span class="hl-type">Vec</span>&lt;Node&gt;,</code>
<code>}</code></pre>

</figure>
<p><span>Another good use-case is interning, where you have something like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">struct</span> <span class="hl-title class_">NameTable</span> {</code>
<code>    strings: <span class="hl-type">Vec</span>&lt;<span class="hl-type">String</span>&gt;,</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">struct</span> <span class="hl-title class_">Name</span>(<span class="hl-type">u32</span>);</code></pre>

</figure>
<p><span>How do we sort a </span><code>Vec&lt;Name&gt;</code><span>?</span>
<span>We can</span>&rsquo;<span>t use the type class approach here, as knowing the </span><em><span>type</span></em><span> of </span><code>Name</code><span> isn</span>&rsquo;<span>t enough to sort names lexicographically, an instance of </span><code>NameTable</code><span> is also required to fetch the actual string data.</span>
<span>The approach with just passing in comparison function works, as it can close over the correct </span><code>NameTable</code><span> in scope.</span></p>
<p><span>The problem with </span>&ldquo;<span>just pass a function</span>&rdquo;<span> is that it gets tedious quickly.</span>
<span>Rather than </span><span class="display"><code>xs.print()</code></span><span> you now need to say </span><span class="display"><code>xs.print(Int::print)</code><span>.</span></span>
<span>Luckily, similarly to how the compiler infers the type parameter </span><code>T</code><span> by default, we can allow limited inference of value parameters, which should remove most of the boilerplate.</span>
<span>So, something which looks like </span><span class="display"><code>names.print()</code></span><span> would desugar to </span><span class="display"><code>Vec::print_vec(self.name_table.print, names)</code><span>.</span></span></p>
<p><span>This could also synergize well with compile-time evaluation.</span>
<span>If (as is the common case), the value of the implicit function table is known at compile time, no table needs to be passed in at runtime (and we don</span>&rsquo;<span>t have to repeatedly evaluate the table itself).</span>
<span>We can even compile-time partially evaluate things within the compilation unit, and use runtime parameters at the module boundaries, just like Swift does.</span></p>
<p><span>And that</span>&rsquo;<span>s basically it!</span>
<span>TL;DR: value oriented programming / mutable value semantics is an interesting </span>&ldquo;<span>everything is X</span>&rdquo;<span> approach to get the benefits of functional purity without giving up on mutable hash tables.</span>
<span>This style of programming doesn</span>&rsquo;<span>t work with cyclic data structures (values are always trees), so indexes are often used to express auxiliary relations.</span>
<span>This, however, gets in a way of type-based generic programming </span>&mdash;<span> a </span><code>T</code><span> is no longer </span><code>Comparable</code><span>, only </span><code>T + Context</code><span> is.</span>
<span>A potential fix for that is to base generic programming on explicit dictionary passing combined with implicit value parameter inference.</span></p>
<p><span>Is there a language like this already?</span></p>
<p><span>Links:</span></p>
<ul>
<li>
<a href="https://www.val-lang.dev"><span>Val</span></a>
</li>
<li>
<a href="https://arxiv.org/pdf/1512.01895.pdf"><span>Modular implicits</span></a>
</li>
<li>
<a href="https://rust-lang.github.io/async-fundamentals-initiative/evaluation/design/with_clauses.html"><span>With clauses</span></a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=ctS8FzqcRug"><span>Implementing Swift generics</span></a>
</li>
</ul>
]]></content>
</entry>

<entry>
<title type="text">Data Oriented Parallel Value Interner</title>
<link href="https://matklad.github.io/2023/04/23/data-oriented-parallel-value-interner.html" rel="alternate" type="text/html" title="Data Oriented Parallel Value Interner" />
<published>2023-04-23T00:00:00+00:00</published>
<updated>2023-04-23T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/04/23/data-oriented-parallel-value-interner</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[In this post, I will present a theoretical design for an interner.
It should be fast, but there will be no benchmarks as I haven't implemented the thing.
So it might actually be completely broken or super slow for one reason or another.
Still, I think there are a couple of neat ideas, which I would love to call out.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/04/23/data-oriented-parallel-value-interner.html"><![CDATA[
    <h1>
    <a href="#Data-Oriented-Parallel-Value-Interner"><span>Data Oriented Parallel Value Interner</span> <time datetime="2023-04-23">Apr 23, 2023</time></a>
    </h1>
<p><span>In this post, I will present a theoretical design for an interner.</span>
<span>It should be fast, but there will be no benchmarks as I haven</span>&rsquo;<span>t implemented the thing.</span>
<span>So it might actually be completely broken or super slow for one reason or another.</span>
<span>Still, I think there are a couple of neat ideas, which I would love to call out.</span></p>
<p><span>The context for the post is </span><a href="https://www.youtube.com/watch?v=AqDdWEiSwMM"><span>this talk</span></a><span> by Andrew Kelley, which notices that it</span>&rsquo;<span>s hard to reconcile interning and parallel compilation.</span>
<span>This is something I have been thinking about a lot in the context of rust-analyzer, which relies heavily on pointers, atomic reference counting and indirection to make incremental and parallel computation possible.</span></p>
<p><span>And yes, interning (or, more generally, assigning unique identities to things) is a big part of that.</span></p>
<p><span>Usually, compilers intern strings, but we will be interning trees today.</span>
<span>Specifically, we will be looking at something like a </span><a href="https://github.com/ziglang/zig/blob/b95cdf0aeb4d4d31c0b6a54302ef61baec8f6773/src/value.zig#L20"><code>Value</code></a><span> type from the Zig compiler.</span>
<span>In a simplified RAII style it could look like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> Value = <span class="hl-keyword">union</span>(<span class="hl-keyword">enum</span>) {</code>
<code>    <span class="hl-comment">// A bunch of payload-less variants.</span></code>
<code>    u1_type,</code>
<code>    u8_type,</code>
<code>    i8_type,</code>
<code></code>
<code>    <span class="hl-comment">// A number.</span></code>
<code>    <span class="hl-type">u64</span>: <span class="hl-type">u64</span>,</code>
<code></code>
<code>    <span class="hl-comment">// A declaration.</span></code>
<code>    <span class="hl-comment">// Declarations and types are also values in Zig.</span></code>
<code>    decl: DeclIndex,</code>
<code></code>
<code>    <span class="hl-comment">// Just some bytes for a string.</span></code>
<code>    bytes: []<span class="hl-type">u8</span>,</code>
<code></code>
<code>    <span class="hl-comment">// The interesting case which makes it a tree.</span></code>
<code>    <span class="hl-comment">// This is how struct instances are represented.</span></code>
<code>    aggregate: []Value,</code>
<code>};</code>
<code></code>
<code><span class="hl-keyword">const</span> DeclIndex = <span class="hl-type">u32</span>;</code></pre>

</figure>
<p><span>Such values are individually heap-allocated and in general are held behind pointers.</span>
<span>Zig</span>&rsquo;<span>s compiler adds a couple of extra tricks to this structure, like not overallocating for small enum variants:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> Value = <span class="hl-keyword">struct</span> {</code>
<code>    payload: <span class="hl-operator">*</span>Payload</code>
<code>}</code>
<code></code>
<code><span class="hl-comment">// Payload is an &quot;abstract&quot; type:</span></code>
<code><span class="hl-comment">// There&#x27;s some data following the `tag`,</span></code>
<code><span class="hl-comment">// whose type and size is determined by</span></code>
<code><span class="hl-comment">// this `tag`.</span></code>
<code><span class="hl-keyword">const</span> Payload = <span class="hl-keyword">struct</span> {</code>
<code>    tag: Tag,</code>
<code></code>
<code>    <span class="hl-keyword">pub</span> <span class="hl-keyword">const</span> U64 = <span class="hl-keyword">struct</span> {</code>
<code>        base: Payload,</code>
<code>        data: <span class="hl-type">u64</span>,</code>
<code>    };</code>
<code></code>
<code>    <span class="hl-keyword">pub</span> <span class="hl-keyword">const</span> Decl = <span class="hl-keyword">struct</span> {</code>
<code>        base: Payload,</code>
<code>        decl: DeclIndex,</code>
<code>    };</code>
<code>}</code></pre>

</figure>
<p><span>But how do we intern this stuff, such that:</span></p>
<ul>
<li>
<span>values are just </span><code>u32</code><span> rather than full pointers,</span>
</li>
<li>
<span>values are deduplicated,</span>
</li>
<li>
<span>and this whole construct works efficiently even if there are multiple threads</span>
<span>using our interner simultaneously?</span>
</li>
</ul>
<p><span>Let</span>&rsquo;<span>s start with concurrent </span><code>SegmentedList</code><span>:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span><span class="hl-function"> SegmentList</span>(<span class="hl-keyword">comptime</span> T: <span class="hl-type">type</span>) <span class="hl-type">type</span> {</code>
<code>    <span class="hl-keyword">return</span> <span class="hl-keyword">struct</span> {</code>
<code>        echelons: [<span class="hl-numbers">31</span>]?[<span class="hl-operator">*</span>]T,</code>
<code>    };</code>
<code>}</code></pre>

</figure>
<p><span>Segmented list is like </span><code>ArrayList</code><span> with an extra super power that pushing new items does not move/invalidate old ones.</span>
<span>In normal </span><code>ArrayList</code><span>, when the backing storage fills up, you allocate a slice twice as long, copy over the elements from the old slice and then destroy it.</span>
<span>In </span><code>SegmentList</code><span>, you leave the old slice where it is, and just allocate a new one.</span></p>
<p><span>Now, as we are writing an interner and want to use </span><code>u32</code><span> for an index, we know that we need to store </span><code>1&lt;&lt;32</code><span> items max.</span>
<span>But that means that we</span>&rsquo;<span>ll need at most 31 segments for our </span><code>SegmentList</code><span>:</span></p>

<figure class="code-block">


<pre><code>[1 &lt;&lt; 0]T</code>
<code>[1 &lt;&lt; 1]T</code>
<code>[1 &lt;&lt; 2]T</code>
<code>...</code>
<code>[1 &lt;&lt; 31]T</code></pre>

</figure>
<p><span>So we can just </span>&ldquo;<span>pre-allocate</span>&rdquo;<span> array of 31 </span><em><span>pointers</span></em><span> to the segments, hence</span></p>

<figure class="code-block">


<pre><code>echelons: [<span class="hl-numbers">31</span>]?[<span class="hl-operator">*</span>]T,</code></pre>

</figure>
<p><span>If we want to be more precise with types, we can even use a tuple whose elements are nullable pointers to arrays of power-of-two sizes:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span><span class="hl-function"> SegmentList</span>(<span class="hl-keyword">comptime</span> T: <span class="hl-type">type</span>) <span class="hl-type">type</span> {</code>
<code>    <span class="hl-keyword">return</span> <span class="hl-keyword">struct</span> {</code>
<code>        echelons: std.meta.Tuple(get_echelons(<span class="hl-numbers">31</span>, T)),</code>
<code>    };</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span><span class="hl-function"> get_echelons</span>(</code>
<code>    <span class="hl-keyword">comptime</span> level: <span class="hl-type">usize</span>,</code>
<code>    <span class="hl-keyword">comptime</span> T: <span class="hl-type">type</span>,</code>
<code>) []<span class="hl-keyword">const</span> <span class="hl-type">type</span> {</code>
<code>    <span class="hl-keyword">if</span> (level <span class="hl-operator">==</span> <span class="hl-numbers">0</span>) <span class="hl-keyword">return</span> <span class="hl-operator">&amp;</span>.{ ?<span class="hl-operator">*</span>[<span class="hl-numbers">1</span>]T };</code>
<code>    <span class="hl-keyword">return</span> get_echelons(level <span class="hl-operator">-</span> <span class="hl-numbers">1</span>, T) <span class="hl-operator">+</span><span class="hl-operator">+</span> .{ ?<span class="hl-operator">*</span>[<span class="hl-numbers">1</span> <span class="hl-operator">&lt;&lt;</span> level]T };</code>
<code>}</code></pre>

</figure>
<p><span>Indexing into such an echeloned array is still O(1).</span>
<span>Here</span>&rsquo;<span>s how echelons look in terms of indexes</span></p>

<figure class="code-block">


<pre><code>0                      = 1  total</code>
<code>1 2                    = 3  total</code>
<code>3 4 5 6                = 7  total</code>
<code>7 8 9 10 11 12 13 14   = 15 total</code></pre>

</figure>
<p><span>The first </span><code>n</code><span> echelons hold </span><code>2**n - 1</code><span> elements.</span>
<span>So, if we want to find the </span><code>i</code><span>th item, we first find the echelon it is in, by computing the nearest smaller power of two of </span><code>i + 1</code><span>, and then index into the echelon with </span><code>i - (2**n - 1)</code><span>, give or take a </span><code>+1</code><span> here or there.</span></p>

<figure class="code-block">


<pre><code><span class="hl-comment">// Warning: untested, probably has a couple of bugs.</span></code>
<code></code>
<code><span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span><span class="hl-function"> get</span>(self: Self, index: <span class="hl-type">u32</span>) <span class="hl-operator">*</span><span class="hl-keyword">const</span> T {</code>
<code>    <span class="hl-keyword">const</span> e = self.get_echelon(index);</code>
<code>    <span class="hl-keyword">const</span> i = index <span class="hl-operator">-</span> (<span class="hl-numbers">1</span> <span class="hl-operator">&lt;&lt;</span> e <span class="hl-operator">-</span> <span class="hl-numbers">1</span>);</code>
<code>    <span class="hl-keyword">return</span> <span class="hl-operator">&amp;</span>self.echelons[e].?[i];</code>
<code>}</code>
<code></code>
<code><span class="hl-keyword">fn</span><span class="hl-function"> get_echelon</span>(index: <span class="hl-type">u32</span>) <span class="hl-type">u5</span> {</code>
<code>    <span class="hl-built_in">@ctz</span>(std.math.floorPowerOfTwo(index <span class="hl-operator">+</span> <span class="hl-numbers">1</span>));</code>
<code>}</code></pre>

</figure>
<p><span>Note that we pre-allocate an array of pointers to segments, but not the segments themselves.</span>
<span>Pointers are nullable, and we allocate new segments lazily, when we actually write to the corresponding indexes.</span>
<span>This structure is very friendly to parallel code.</span>
<span>Reading items works because items are never reallocated.</span>
<span>Lazily allocating new echelons is easy, because the position of the pointer is fixed.</span>
<span>That is, we can do something like this to insert an item at position </span><code>i</code><span>:</span></p>
<ol>
<li>
<span>compute the echelon index</span>
</li>
<li>
<code>@atomicLoad(.Acquire)</code><span> the pointer</span>
</li>
<li>
<span>if the pointer is null</span>
<ul>
<li>
<span>allocate the echelon</span>
</li>
<li>
<code>@cmpxchgStrong(.Acquire, .Release)</code><span> the pointer</span>
</li>
<li>
<span>free the redundant echelon if exchange failed</span>
</li>
</ul>
</li>
<li>
<span>insert the item</span>
</li>
</ol>
<p><span>Notice how we don</span>&rsquo;<span>t need any locks or even complicated atomics, at the price of sometimes doing a second redundant allocation.</span></p>
<p><span>One thing this data structure is bad at is doing bounds checks and tracking which items are actually initialized.</span>
<span>For the interner use-case, we will rely on an invariant that we always use indexes provided to use by someone else, such that possession of the index signifies that:</span></p>
<ul>
<li>
<span>the echelon holding the item is allocated</span>
</li>
<li>
<span>the item itself is initialized</span>
</li>
<li>
<span>there</span>&rsquo;<span>s the relevant happens-before established</span>
</li>
</ul>
<p><span>If, instead, we manufacture an index out of thin air, we might hit all kinds of nasty behavior without any bullet-proof way to check that.</span></p>
<p><span>Okay, now that we have this </span><code>SegmentList</code><span>, how would we use them?</span></p>
<p><span>Recall that our simplified value is</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> Value = <span class="hl-keyword">union</span>(<span class="hl-keyword">enum</span>) {</code>
<code>    <span class="hl-comment">// A bunch of payload-less variants.</span></code>
<code>    u1_type,</code>
<code>    u8_type,</code>
<code>    i8_type,</code>
<code></code>
<code>    <span class="hl-comment">// A number.</span></code>
<code>    <span class="hl-type">u64</span>: <span class="hl-type">u64</span>,</code>
<code></code>
<code>    <span class="hl-comment">// A declaration.</span></code>
<code>    <span class="hl-comment">// Declarations and types are also values in Zig.</span></code>
<code>    decl: Decl,</code>
<code></code>
<code>    <span class="hl-comment">// Just some bytes for a string.</span></code>
<code>    bytes: []<span class="hl-type">u8</span>,</code>
<code></code>
<code>    <span class="hl-comment">// The interesting case which makes it a tree.</span></code>
<code>    <span class="hl-comment">// This is how struct instances are represented.</span></code>
<code>    aggregate: []Value,</code>
<code>};</code>
<code></code>
<code><span class="hl-comment">// Index of a declaration.</span></code>
<code><span class="hl-keyword">const</span> Decl = <span class="hl-type">u32</span>;</code></pre>

</figure>
<p><span>Of course we will struct-of-array it now, to arrive at something like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> Value = <span class="hl-type">u32</span>;</code>
<code></code>
<code><span class="hl-keyword">const</span> Tag = <span class="hl-keyword">enum</span>(<span class="hl-type">u8</span>) {</code>
<code>    u1_type, u8_type, i8_type,</code>
<code>    <span class="hl-type">u64</span>, decl, bytes, aggregate,</code>
<code>};</code>
<code></code>
<code><span class="hl-keyword">const</span> ValueTable = <span class="hl-keyword">struct</span> {</code>
<code>    tag: SegmentList(Tag),</code>
<code>    data: SegmentList(<span class="hl-type">u32</span>),</code>
<code></code>
<code>    <span class="hl-type">u64</span>: SegmentList(<span class="hl-type">u64</span>),</code>
<code>    aggregate: SegmentList([]Value),</code>
<code>    bytes: SegmentList([]<span class="hl-type">u8</span>),</code>
<code>};</code></pre>

</figure>
<p><span>A </span><code>Value</code><span> is now an index.</span>
<span>This index works for two fields of </span><code>ValueTable</code><span>, </span><code>tag</code><span> and </span><code>data</code><span>.</span>
<span>That is, the index addresses five bytes of payload, which is all that is needed for small values.</span>
<span>For large tags like </span><code>aggregate</code><span>, the </span><code>data</code><span> field stores an index into the corresponding payload </span><code>SegmentList</code><span>.</span></p>
<p><span>That is, every value allocates a </span><code>tag</code><span> and </span><code>data</code><span> elements, but only actual </span><code>u64</code><span>s occupy a slot in </span><code>u64</code><span> </span><code>SegmentList</code><span>.</span></p>
<p><span>So now we can write a </span><code>lookup</code><span> function which takes a value index and reconstructs a value from pieces:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> ValueFull = <span class="hl-keyword">union</span>(<span class="hl-keyword">enum</span>) {</code>
<code>    u1_type,</code>
<code>    u8_type,</code>
<code>    i8_type,</code>
<code>    <span class="hl-type">u64</span>: <span class="hl-type">u64</span>,</code>
<code>    decl: Decl,</code>
<code>    bytes: []<span class="hl-type">u8</span>,</code>
<code>    aggregate: []Value,</code>
<code>};</code>
<code></code>
<code><span class="hl-keyword">fn</span><span class="hl-function"> lookup</span>(self: Self, value: Value) ValueFull {</code>
<code>    <span class="hl-keyword">const</span> tag = self.tag.get(value);</code>
<code>    <span class="hl-keyword">switch</span> (tag) {</code>
<code>        .aggregate =&gt; <span class="hl-keyword">return</span> ValueFull{</code>
<code>            .aggregate = self.aggregate.get(self.data(value)),</code>
<code>        },</code>
<code>    }</code>
<code>}</code></pre>

</figure>
<p><span>Note that here </span><code>ValueFull</code><span> is non-owning type, it is a </span><em><span>reference</span></em><span> into the actual data.</span>
<span>Note as well that aggregates now store a slice of indexes, rather than a slice of pointers.</span></p>
<p><span>Now let</span>&rsquo;<span>s deal with creating and interning values.</span>
<span>We start by creating a </span><code>ValueFull</code><span> using data owned by us</span>
<span>(e.g. if we are creating an aggregate, we may use a stack-allocated array as a backing store for </span><code>[]Value</code><span> slice).</span>
<span>Then we ask </span><code>ValueTable</code><span> to intern the data:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span><span class="hl-function"> intern</span>(self: <span class="hl-operator">*</span>Self, value_full: ValueFull) Value {</code>
<code>}</code></pre>

</figure>
<p><span>If the table already contains an equal value, its index is returned.</span>
<span>Otherwise, the table </span><em><span>copies</span></em><span> </span><code>ValueFull</code><span> data such that it is owned by the table itself, and returns a freshly allocated index.</span></p>
<p><span>For bookkeeping, we</span>&rsquo;<span>ll need a hash table with existing values and a counter to use for a fresh index, something like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> ValueTable = <span class="hl-keyword">struct</span> {</code>
<code>    value_set: AutoHashMapUnmanaged(Value, <span class="hl-type">void</span>),</code>
<code>    value_count: <span class="hl-type">u32</span>,</code>
<code>    tag: SegmentList(Tag),</code>
<code>    index: SegmentList(<span class="hl-type">u32</span>),</code>
<code></code>
<code>    u64_count: <span class="hl-type">u32</span>,</code>
<code>    <span class="hl-type">u64</span>: SegmentList(<span class="hl-type">u64</span>),</code>
<code></code>
<code>    aggregate_count: <span class="hl-type">u32</span>,</code>
<code>    aggregate: SegmentList([]Value),</code>
<code></code>
<code>    bytes_count: <span class="hl-type">u32</span>,</code>
<code>    bytes: SegmentList([]<span class="hl-type">u8</span>),</code>
<code></code>
<code>    <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span><span class="hl-function"> intern</span>(self: <span class="hl-operator">*</span>Self, value_full: ValueFull) Value {</code>
<code>        ...</code>
<code>    }</code>
<code>};</code></pre>

</figure>
<p><span>Pay attention to </span><code>_count</code><span> fields </span>&mdash;<span> we have </span><code>value_count</code><span> guarding the </span><code>tag</code><span> and </span><code>index</code><span>, and separate counts for specific kinds of values, as we don</span>&rsquo;<span>t want to allocate, e.g. an </span><code>u64</code><span> for </span><em><span>every</span></em><span> value.</span></p>
<p><span>Our hashmap is actually a set which stores </span><code>u32</code><span> integers, but uses </span><code>ValueFull</code><span> to do a lookup: when we consider interning a new </span><code>ValueFull</code><span>, we don</span>&rsquo;<span>t know its index yet.</span>
<span>Luckily, </span><code>getOrPutAdapted</code><span> API provides the required flexibility.</span>
<span>We can use it to compare a </span><code>Value</code><span> (index) and a </span><code>ValueFull</code><span> by hashing a </span><code>ValueFull</code><span> and doing component-wise comparisons in the case of a collision.</span></p>
<p><span>Note that, because of interning, we can also hash </span><code>ValueFull</code><span> efficiently!</span>
<span>As any subvalues in </span><code>ValueFull</code><span> are guaranteed to be already interned, we can rely on shallow hash and hash only child value</span>&rsquo;<span>s indexes, rather than their data.</span></p>
<p><span>This is a nice design for a single thread, but how do we make it thread safe?</span>
<span>The straightforward solution would be to slap a mutex around the logic in </span><code>intern</code><span>.</span></p>
<p><span>This actually is not as bad as it seems, as we</span>&rsquo;<span>d need a lock only in </span><code>intern</code><span>, and </span><code>lookup</code><span> would work without any synchronization whatsoever.</span>
<span>Recall that obtaining an index of a value is a proof that the value was properly published.</span>
<span>Still, we expect to intern a lot of values, and that mutex is all but guaranteed to become a point of contention.</span>
<span>And some amount of contention is inevitable here </span>&mdash;<span> if two threads try to intern two identical values, we </span><em><span>want</span></em><span> them to clash, communicate, and end up with a single, shared value.</span></p>
<p><span>There</span>&rsquo;<span>s a rather universal recipe for dealing with contention </span>&mdash;<span> you can shard the data.</span>
<span>In our case, rather than using something like</span></p>

<figure class="code-block">


<pre><code>mutex: Mutex,</code>
<code>value_set: AutoHashMapUnmanaged(Value, <span class="hl-type">void</span>),</code></pre>

</figure>
<p><span>we can do</span></p>

<figure class="code-block">


<pre><code>mutex: [<span class="hl-numbers">16</span>]Mutex,</code>
<code>value_set: [<span class="hl-numbers">16</span>]AutoHashMapUnmanaged(Value, <span class="hl-type">void</span>),</code></pre>

</figure>
<p><span>That is, we create not one, but sixteen hashmaps, and use, e.g., lower 4 bits of the hash to decide which mutex and hashmap to use.</span>
<span>Depending on the structure of the hashmap, such locks could even be pushed as far as individual buckets.</span></p>
<p><span>This doesn</span>&rsquo;<span>t solve all our contention problems </span>&mdash;<span> now that several threads can simultaneously intern values (as long as they are hashed into different shards) we have to make all </span><code>count</code><span> variables atomic.</span>
<span>So we essentially moved the single global point of contention from a mutex to </span><code>value_count</code><span> field, which is incremented for every interned value.</span></p>
<p><span>We can apply the sharding trick again, and shard all our </span><code>SegmentList</code><span>s.</span>
<span>But that would mean that we have to dedicate some bits from </span><code>Value</code><span> index to the shard number, and to waste some extra space for non-perfectly balanced shards.</span></p>
<p><span>There</span>&rsquo;<span>s a better way </span>&mdash;<span> we can amortize atomic increments by allowing each thread to bulk-allocate indexes.</span>
<span>That is, if a thread wants to allocate a new value, it atomically increments </span><code>value_cont</code><span> by, say, </span><code>1024</code><span>, and uses those indexes for the next thousand allocations.</span>
<span>In addition to </span><code>ValueTable</code><span>, each thread now gets its own distinct </span><code>LocalTable</code><span>:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">const</span> LocalTable = <span class="hl-keyword">struct</span> {</code>
<code>    global: <span class="hl-operator">*</span>ValueTable,</code>
<code></code>
<code>    <span class="hl-comment">// Invariant: if any `index % 1024 == 0`,</span></code>
<code>    <span class="hl-comment">// it&#x27;s time to visit `global` to</span></code>
<code>    <span class="hl-comment">// refill our budget via atomic fetchAndAdd.</span></code>
<code>    value_index: <span class="hl-type">u32</span>,</code>
<code>    u64_index: <span class="hl-type">u32</span>,</code>
<code>    aggregate_index: <span class="hl-type">u32</span>,</code>
<code>    bytes_index: <span class="hl-type">u32</span>,</code>
<code>};</code></pre>

</figure>
<p><span>An attentive reader would notice a bonus here: in this setup, a thread allocates a contiguous chunk of values.</span>
<span>It is reasonable to assume that values allocated together would also be used together, so we potentially increase future spatial locality here.</span></p>
<p><span>Putting everything together, the pseudo-code for interning would look like this:</span></p>

<figure class="code-block">


<pre><code><span class="hl-keyword">fn</span><span class="hl-function"> intern</span>(table: <span class="hl-operator">*</span>LocalTable, value_full: ValueFull) Value {</code>
<code>    <span class="hl-keyword">const</span> hash = shallow_hash(value_full);</code>
<code></code>
<code>    <span class="hl-comment">// Find &amp; lock the shard.</span></code>
<code>    <span class="hl-keyword">const</span> shard = hash <span class="hl-operator">&amp;</span> <span class="hl-numbers">0xF</span>;</code>
<code>    let mutex = <span class="hl-operator">&amp;</span>table.global.mutex[shard];</code>
<code>    let value_set = <span class="hl-operator">&amp;</span>table.global.value_set[shard]</code>
<code></code>
<code>    mutex.lock();</code>
<code>    <span class="hl-keyword">defer</span> mutex.unlock();</code>
<code></code>
<code>    <span class="hl-comment">// Either find that this value has been interned already...</span></code>
<code>    <span class="hl-keyword">const</span> gop = value_set.get_or_put(hash, value_full, ...);</code>
<code>    <span class="hl-keyword">if</span> (gop.found_existing) <span class="hl-keyword">return</span> got.key_ptr.<span class="hl-operator">*</span>;</code>
<code></code>
<code>    <span class="hl-comment">// ... or proceed to allocate a new index for it</span></code>
<code></code>
<code>    <span class="hl-keyword">if</span> (table.tag_index <span class="hl-operator">&amp;</span> <span class="hl-numbers">0xFF</span> <span class="hl-operator">==</span> <span class="hl-numbers">0</span>) {</code>
<code>        <span class="hl-comment">// Run out of indexes, refill our budget!</span></code>
<code>        table.tag_index = <span class="hl-built_in">@atomicRmw</span>(</code>
<code>            <span class="hl-type">u32</span>, <span class="hl-operator">&amp;</span>table.global.value_count,</code>
<code>            .Add, <span class="hl-numbers">0xFF</span>,</code>
<code>            .Relaxed,</code>
<code>        );</code>
<code>    }</code>
<code></code>
<code>    <span class="hl-comment">// Assign the index to the new value</span></code>
<code>    <span class="hl-comment">// and put it into the hash map.</span></code>
<code>    <span class="hl-keyword">const</span> value = table.tag_index;</code>
<code>    table.tag_index <span class="hl-operator">+=</span> <span class="hl-numbers">1</span>;</code>
<code>    gop.key_ptr.<span class="hl-operator">*</span> = value;</code>
<code></code>
<code>    <span class="hl-comment">// Now initialize the value.</span></code>
<code>    <span class="hl-comment">// Note that we still hold shard&#x27;s mutex at this point.</span></code>
<code></code>
<code>    <span class="hl-keyword">switch</span> (value_full) {</code>
<code>        .aggregate =&gt; <span class="hl-operator">|</span>fields<span class="hl-operator">|</span> {</code>
<code>            <span class="hl-comment">// Initialize the tag, common for all values.</span></code>
<code>            table.global.tag.set(value, .aggregate);</code>
<code></code>
<code>            <span class="hl-comment">// Allocate tag-specific data using</span></code>
<code>            <span class="hl-comment">// the same atomic add trick.</span></code>
<code>            <span class="hl-keyword">if</span> (table.aggregate_index <span class="hl-operator">&amp;</span> <span class="hl-numbers">0xFF</span> <span class="hl-operator">==</span> <span class="hl-numbers">0</span>) {</code>
<code>                table.aggregate_index = <span class="hl-built_in">@atomicRmw</span>(</code>
<code>                    <span class="hl-type">u32</span>, <span class="hl-operator">&amp;</span>table.global.aggregate_count,</code>
<code>                    .Add, <span class="hl-numbers">0xFF</span>,</code>
<code>                    .Relaxed,</code>
<code>                );</code>
<code>            }</code>
<code>            <span class="hl-keyword">const</span> index = table.aggregate_index;</code>
<code>            table.aggregate_index <span class="hl-operator">+=</span> <span class="hl-numbers">1</span>;</code>
<code></code>
<code>            <span class="hl-comment">// Make it possible to find tag-specific data</span></code>
<code>            <span class="hl-comment">// from the value index.</span></code>
<code>            table.global.index.set(value, index);</code>
<code></code>
<code>            <span class="hl-comment">// `value_full` is borrowed, so we must</span></code>
<code>            <span class="hl-comment">// create a copy that we own.</span></code>
<code>            <span class="hl-keyword">const</span> fields_owned = allocator.dup(fields)</code>
<code>                <span class="hl-keyword">catch</span> <span class="hl-keyword">unreachable</span>;</code>
<code></code>
<code>            table.global.aggregate.set(index, fields_owned);</code>
<code>        }</code>
<code>    }</code>
<code></code>
<code>    <span class="hl-keyword">return</span> value;</code>
<code>}</code>
<code></code>
<code><span class="hl-comment">// Code for assigning an index of a SegmentList.</span></code>
<code><span class="hl-comment">// Shard&#x27;s mutex guarantees exclusive access to the index.</span></code>
<code><span class="hl-comment">// Accesses to the echelon might race though.</span></code>
<code><span class="hl-keyword">fn</span><span class="hl-function"> set</span>(list: SegmentList(T), index: <span class="hl-type">u32</span>, value: T) {</code>
<code>    <span class="hl-keyword">const</span> e = list.get_echelon(index);</code>
<code>    <span class="hl-keyword">const</span> i = index <span class="hl-operator">-</span> ((<span class="hl-numbers">1</span> <span class="hl-operator">&lt;&lt;</span> e) <span class="hl-operator">-</span> <span class="hl-numbers">1</span>);</code>
<code></code>
<code>    <span class="hl-keyword">var</span> echelon = <span class="hl-built_in">@atomicLoad</span>(?[<span class="hl-operator">*</span>]T, <span class="hl-operator">&amp;</span>list.echelons[e], .Acquire);</code>
<code>    <span class="hl-keyword">if</span> (echelon <span class="hl-operator">==</span> <span class="hl-literal">null</span>) {</code>
<code>        <span class="hl-comment">// Race with other threads to allocate the echelon.</span></code>
<code>        <span class="hl-keyword">const</span> echelon_new = allocator.alloc(T, <span class="hl-numbers">1</span> <span class="hl-operator">&lt;&lt;</span> e)</code>
<code>            <span class="hl-keyword">catch</span> <span class="hl-keyword">unreachable</span>;</code>
<code></code>
<code>        <span class="hl-keyword">const</span> modified = <span class="hl-built_in">@cmpxchgStrong</span>(</code>
<code>            ?[<span class="hl-operator">*</span>]T, <span class="hl-operator">&amp;</span>list.echelons[e],</code>
<code>            <span class="hl-literal">null</span>, echelon_new,</code>
<code>            .Release, .Acquire,</code>
<code>        );</code>
<code></code>
<code>        <span class="hl-keyword">if</span> (modified) <span class="hl-operator">|</span>echelon_modified<span class="hl-operator">|</span> {</code>
<code>            <span class="hl-comment">// Another thread won, free our useless allocation.</span></code>
<code>            echelon = echelon_modified</code>
<code>            allocator.free(echelon_new);</code>
<code>        } <span class="hl-keyword">else</span> {</code>
<code>            echelon = echelon_new;</code>
<code>        }</code>
<code>    }</code>
<code></code>
<code>    echelon.?[i] = value;</code>
<code>}</code></pre>

</figure>
<p><span>Note that it is important that we </span><em><span>don</span>&rsquo;<span>t</span></em><span> release the mutex immediately after assigning the index for a value, but rather keep it locked all the way until we fully copied thee value into the </span><code>ValueTable</code><span>.</span>
<span>If we release the lock earlier, a different thread which tries to intern the same value would get the correct index, but would risk accessing partially-initialized data.</span>
<span>This can be optimized a bit by adding value-specific lock (or rather, a </span><a href="https://github.com/ziglang/zig/blob/b95cdf0aeb4d4d31c0b6a54302ef61baec8f6773/lib/std/once.zig"><code>Once</code></a><span>).</span>
<span>So we use the shard lock to assign an index, then release the shard lock, and use value-specific lock to do the actual (potentially slow) initialization.</span></p>
<p><span>And that</span>&rsquo;<span>s all I have for today!</span>
<span>Again, I haven</span>&rsquo;<span>t implemented this, so I have no idea how fast or slow it actually is.</span>
<span>But the end result looks rather beautiful, and builds upon many interesting ideas:</span></p>
<ul>
<li>
<p><code>SegmentList</code><span> allows to maintain index stability despite insertions.</span></p>
</li>
<li>
<p><span>There will be at most 31 echelons in a </span><code>SegmentList</code><span>, so you can put pointes to them into an array, removing the need to synchronize to read an echelon.</span></p>
</li>
<li>
<p><span>With this setup, it becomes easy to initialize a new echelon with a single CAS.</span></p>
</li>
<li>
<p><span>Synchronization is required only when creating a new item.</span>
<span>If you trust indexes, you can use them to carry happens-before.</span></p>
</li>
<li>
<p><span>In a struct-of-arrays setup for enums, you can save space by requiring that an array for a specific variant is just as long as it needs to be.</span></p>
</li>
<li>
<p><span>One benefit of interning trees is that hash function becomes a shallow operation.</span></p>
</li>
<li>
<p><span>Optimal interners use hashmaps in a fancy way, where the key is not what you actually store in the hashmap.</span>
<span>I have two related posts about that,</span>
<a href="https://matklad.github.io/2020/03/22/fast-simple-rust-interner.html"><em><span>Fast and Simple Rust Interner</span></em></a><span> and</span>
<a href="https://matklad.github.io/2020/12/28/csdi.html"><em><span>Call Site Dependency Injection</span></em></a><span>.</span></p>
</li>
<li>
<p><span>Sharding is an effective way to reduce contention if you are dealing with something like a shared hashmap.</span></p>
</li>
<li>
<p><span>For counters, one alternative to sharding is batching up the increments.</span></p>
</li>
</ul>
<p><span>Discussion on </span><a href="https://old.reddit.com/r/Zig/"><span>/r/Zig</span></a><span>.</span></p>
]]></content>
</entry>

<entry>
<title type="text">Reasonable Bootstrap</title>
<link href="https://matklad.github.io/2023/04/13/reasonable-bootstrap.html" rel="alternate" type="text/html" title="Reasonable Bootstrap" />
<published>2023-04-13T00:00:00+00:00</published>
<updated>2023-04-13T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/04/13/reasonable-bootstrap</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[Compilers for systems programming languages (C, C++, Rust, Zig) tend to be implemented in the languages themselves.
The idea being that the current version of the compiler is built using some previous version.
But how can you get a working compiler if you start out from nothing?]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/04/13/reasonable-bootstrap.html"><![CDATA[
    <h1>
    <a href="#Reasonable-Bootstrap"><span>Reasonable Bootstrap</span> <time datetime="2023-04-13">Apr 13, 2023</time></a>
    </h1>
<p><span>Compilers for systems programming languages (C, C++, Rust, Zig) tend to be implemented in the languages themselves.</span>
<span>The idea being that the current version of the compiler is built using some previous version.</span>
<span>But how can you get a working compiler if you start out from nothing?</span></p>
<p><span>The traditional answer has been </span>&ldquo;<span>via bootstrap chain</span>&rdquo;<span>.</span>
<span>You start with the first version of the compiler implemented in assembly, use that to compile the latest version of the compiler it is capable of compiling, then repeat.</span>
<span>This historically worked OK because older versions of GCC were implemented in C (and C is easy to provide a compiler for) and, even today, GCC itself is very conservative in using language features.</span>
<span>I believe GCC 10.4 released in 2022 can be built with just a C++98 compiler.</span>
<span>So, if you start with a C compiler, it</span>&rsquo;<span>s not too many hops to get to the latest GCC.</span></p>
<p><span>This doesn</span>&rsquo;<span>t feel entirely satisfactory, as this approach requires artificially constraining the compiler itself to be very conservative.</span>
<span>Rust does the opposite of that.</span>
<span>Rust requires that rustc 1.x.0 is built by rustc 1.x-1.0, and there</span>&rsquo;<span>s a new rustc version every six weeks.</span>
<span>This seems like a very reasonable way to build compilers, </span><em><span>but</span></em><span> it also is incompatible with chain bootstrapping.</span>
<span>In the limit, one would need infinite time to compile modern rustc ex nihilo!</span></p>
<p><span>I </span><em><span>think</span></em><span> there</span>&rsquo;<span>s a better way if the goal is to compile the world from nothing.</span>
<span>To cut to the chase, the minimal bootstrap seed for Rust could be:</span></p>
<ul>
<li>
<span>source code for current version of the compiler</span>
</li>
<li>
<span>this source code compiled to core WebAssembly</span>
</li>
</ul>
<p><span>Bootstrapping from this should be easy.</span>
<span>WebAssembly is a very small language, so a runtime for it can be built out of nothing.</span>
<span>Using this runtime, and rustc-compiled-to-wasm we can re-compile rustc itself.</span>
<span>Then, we can either cross-compile it to the architecture we need, if that architecture is supported by rustc.</span>
<span>If the architecture is </span><em><span>not</span></em><span> supported, we can implement a new backend for that arch in Rust, compile our modified compiler to wasm, and then cross-compile to the desired target.</span></p>
<p><span>More complete bootstrap seed would include:</span></p>
<ul>
<li>
<span>Informal specification of the Rust language, to make sense of the source code.</span>
</li>
<li>
<span>Rust source code for the compiler, which also doubles as a formal specification of the language.</span>
</li>
<li>
<span>Informal specification of WebAssembly, to make sense of .wasm parts of the bootstrap seed.</span>
</li>
<li>
<span>.wasm code for the rust compiler, which triple-checks the Rust specification.</span>
</li>
<li>
<span>Rust implementation of a WebAssembly interpreter, which doubles as a formal spec for WebAssembly.</span>
</li>
</ul>
<p><span>And this seed is provided for every version of a language.</span>
<span>This way, it is possible to bootstrap, in constant time, any version of Rust.</span></p>
<p><span>Specific properties we use for this setup:</span></p>
<ul>
<li>
<span>Compilation is deterministic.</span>
<span>Compiling bootstrap sources with bootstrap .wasm blob should result in a byte-for-byte identical wasm blob.</span>
</li>
<li>
<span>WebAssembly is target-agnostic.</span>
<span>It describes abstract computation, which is completely independent from the host architecture.</span>
</li>
<li>
<span>WebAssembly is simple.</span>
<span>Implementing a WebAssembly interpreter is easy in whatever computation substrate you have.</span>
</li>
<li>
<span>Compiler is a cross compiler.</span>
<span>We don</span>&rsquo;<span>t want to bootstrap </span><em><span>just</span></em><span> the WebAssembly backend, we want to bootstrap everything.</span>
<span>This requires that the WebAssembly version of the compiler can generate the code for arbitrary architectures.</span>
</li>
</ul>
<p><span>This setup does not prevent the trusting trust attack.</span>
<span>However, it is possible to rebuild the bootstrap seed using a different compiler.</span>
<span>Using that compiler to compiler rustc to .wasm will produce a different blob.</span>
<span>But using that .wasm to recompile rustc again should produce the blob from the seed (unless, of course, there</span>&rsquo;<span>s a trojan in the seed).</span></p>
<p><span>This setup does not minimize the size of opaque binary blobs in the seed.</span>
<span>The size of the .wasm would be substantial.</span>
<span>This setup, however, does minimize the total size of the seed.</span>
<span>In the traditional bootstrap, source code for rustc 1.0.0, rustc 1.1.0, rustc 1.2.0, etc would also have to be part of the seed.</span>
<span>For the suggested approach, you need only one version, at the cost of a bigger binary blob.</span></p>
<p><span>This idea is not new.</span>
<span>I </span><em><span>think</span></em><span> it was popularized by Pascal with p-code.</span>
<span>OCaml uses a similar strategy.</span>
<span>Finally, </span><a href="https://ziglang.org/news/goodbye-cpp/"><span>Zig</span></a><span> makes an important observation that we no longer need to implement language-specific virtual machines, because WebAssembly is a good fit for the job.</span></p>
]]></content>
</entry>

</feed>
